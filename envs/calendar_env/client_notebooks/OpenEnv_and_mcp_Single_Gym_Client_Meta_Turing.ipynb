{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qFCLLUZ8E_T"
      },
      "source": [
        "# OpenEnv Benchmark Executor\n",
        "\n",
        "## Eval script for OpenEnv & MCP Environments\n",
        "\n",
        "**Last Updated:** January 2026  \n",
        "**Prepared by:** Turing\n",
        "\n",
        "---\n",
        "\n",
        "### Overview\n",
        "\n",
        "This notebook provides a **self-contained, production-ready eval system** for evaluating AI agents interacting with OpenEnv or MCP gym environments.\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **Dual Protocol Support** - OpenEnv REST API + MCP JSON-RPC\n",
        "- **Multi-LLM Support** - Anthropic, OpenAI, Google via LangChain\n",
        "- **Flexible Database Seeding** - Use custom .sql files or gym's api/sample-data\n",
        "- **Multiple Verifier Types** - database_state, response_check\n",
        "- **Multi-Run Statistics** - Pass@n, success rates, performance metrics\n",
        "\n",
        "### Execution Modes\n",
        "\n",
        "- **OpenEnv Mode** (`execution_mode: \"openenv\"`) - REST API with /reset, /step, /state endpoints\n",
        "- **MCP Mode** (`execution_mode: \"mcp\"`) - JSON-RPC 2.0 protocol with session management\n",
        "\n",
        "### Database Seeding\n",
        "\n",
        "- **Custom SQL File**: Set `seed_database_file: \"path/to/file.sql\"` to seed from your own SQL file\n",
        "- **Gym Sample Data**: Set `seed_database_file: \"\"` (empty) to use the gym's built-in api/sample-data\n",
        "\n",
        "### Installation\n",
        "\n",
        "Run the next cell to install dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB24I46k-S8Y"
      },
      "source": [
        "## Prerequisites for Running on Google Colab\n",
        "\n",
        "### Step 1: Setup MCP Gym Server Locally\n",
        "\n",
        "1. **Download the Openenv gym**\n",
        "   - Download the openenv gym environemnt `calendar_env` folder\n",
        "\n",
        "2. **Run the gym environment Locally**\n",
        "   ### Docker (Recommended)\n",
        "   ```bash\n",
        "   cd calendar_env\n",
        "   docker build -t calendar-env:latest .\n",
        "   docker run --rm -p 8004:8004 calendar-env:latest\n",
        "   curl http://localhost:8004/health\n",
        "   ```\n",
        "   On Server health success response will be:\n",
        "   `{\"status\":\"healthy\",\"service\":\"calendar-env\"}`\n",
        "\n",
        "   ### Without Docker\n",
        "\n",
        "   ```bash\n",
        "   cd calendar_env\n",
        "   python3 -m venv venv\n",
        "   source venv/bin/activate\n",
        "   pip install -r requirements.txt\n",
        "   uvicorn server.app:app --host 0.0.0.0 --port 8004\n",
        "   ```\n",
        "\n",
        "3. **Install Cloudflare Tunnel** (If you want to run this notebook on colab)\n",
        "   ```bash\n",
        "   # Install cloudflared\n",
        "   # macOS\n",
        "   brew install cloudflare/cloudflare/cloudflared\n",
        "   \n",
        "   # Linux\n",
        "   wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "   sudo dpkg -i cloudflared-linux-amd64.deb\n",
        "   \n",
        "   # Windows\n",
        "   # Download from: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/install-and-setup/installation/\n",
        "   ```\n",
        "\n",
        "4. **Expose Server with Cloudflare Tunnel**\n",
        "   ```bash\n",
        "   cloudflared tunnel --url http://localhost:8004\n",
        "   ```\n",
        "   \n",
        "   This will output something like:\n",
        "   ```\n",
        "   +--------------------------------------------------------------------------------------------+\n",
        "   |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
        "   |  https://randomly-generated-subdomain.trycloudflare.com                                      |\n",
        "   +--------------------------------------------------------------------------------------------+\n",
        "   ```\n",
        "\n",
        "5. **Copy the HTTPS URL**\n",
        "   - Copy the `https://` URL from the terminal output\n",
        "   - Use this URL in the configuration in the below cell number 17: for the value of `gym_enviornment_url`\n",
        "\n",
        "### Step 2: Database Seeding Configuration\n",
        "\n",
        "The notebook supports two ways to seed the database:\n",
        "\n",
        "\n",
        "#### Option A: Use Gym's Sample Data in below cell number 17 (Recommended)\n",
        "```python\n",
        "CONFIG = {\n",
        "    ...\n",
        "    \"seed_database_file\": \"\",  # Leave empty for default database\n",
        "    ...\n",
        "}\n",
        "```\n",
        "\n",
        "#### Option B: Use Custom SQL File in below cell number 17 (To create custom data based on gym's tool schema)\n",
        "```python\n",
        "CONFIG = {\n",
        "    ...\n",
        "    \"seed_database_file\": \"path/to/your/custom_seed.sql\",  # Provide SQL file path\n",
        "    ...\n",
        "}\n",
        "```\n",
        "Download sample sql file from the github and upload in the notebook's folder section. Then copy the path and assign the path to `seed_database_file`.\n",
        "- If you provide a `seed_database_file` path, the notebook will:\n",
        "  - Read the SQL content from your custom file\n",
        "  - Create the database with your custom SQL schema and data\n",
        "\n",
        "### Step 3: Configure LLM provider and API key\n",
        "\n",
        "1. **Set API Keys in Colab Secrets**\n",
        "   - Click the 'key' icon in the left sidebar\n",
        "   - Add your LLM API key:\n",
        "     - `LLM_API_KEY`\n",
        "\n",
        "2. **Update Configuration (Cell 5)**\n",
        "   - Configure your LLM provider and model in below cell number 17\n",
        "   - Add any context headers needed (e.g., `x-access-token`)\n",
        "\n",
        "### Example Configuration for Colab\n",
        "\n",
        "```python\n",
        "from google.colab import userdata\n",
        "\n",
        "CONFIG = {\n",
        "    \"execution_mode\": \"openenv\",\n",
        "    \"gym_enviornment_url\": \"https://your-tunnel-subdomain.trycloudflare.com\",\n",
        "    \"mcp_endpoint\": \"/mcp\",\n",
        "    \"seed_database_file\": \"\",  # Empty = use gym's sample data, or provide path\n",
        "    \n",
        "    # LLM Configuration\n",
        "    \"llm_provider\": \"anthropic\",\n",
        "    \"llm_model\": \"claude-sonnet-4-5\",\n",
        "    \"llm_api_key\": userdata.get('ANTHROPIC_API_KEY'),\n",
        "    \n",
        "    # Context headers (if needed)\n",
        "    \"context\": {\n",
        "        \"x-access-token\": \"your-access-token-here\",  # Already has x- prefix\n",
        "        \"actingUserId\": \"alice_manager\"  # Will become x-actinguserid\n",
        "    },\n",
        "    ...\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "### Run Collab code snippets by clicking on the Run all option in the menu section.\n",
        "\n",
        "### The final run result's .json file will be created in the folder section of the collab notebook.\n",
        "\n",
        "### Important Notes\n",
        "\n",
        "- **Tunnel Stability**: Cloudflare tunnels are temporary. If disconnected, you'll need to restart the tunnel and get a new URL\n",
        "- **Custom SQL Files**: When using custom SQL files on Colab, upload them first or mount Google Drive\n",
        "- **Database Cleanup**: The notebook automatically creates and deletes databases, so no manual cleanup needed\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NiPAfaaM8E_V",
        "outputId": "ed383032-50a0-4a48-8b28-73206d8dbe56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.4)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
            "Requirement already satisfied: langchain-anthropic in /usr/local/lib/python3.12/dist-packages (1.3.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (4.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx) (0.16.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.13.0)\n",
            "Requirement already satisfied: anthropic<1.0.0,>=0.75.0 in /usr/local/lib/python3.12/dist-packages (from langchain-anthropic) (0.76.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.60.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (0.17.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.48.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: cryptography>=38.0.3 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (43.0.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.23)\n",
            "Dependencies ready\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "!pip install httpx langchain langchain-core langchain-anthropic langchain-openai langchain-google-genai\n",
        "\n",
        "print(\"Dependencies ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAuxddul8E_W"
      },
      "source": [
        "## Configuration Settings\n",
        "\n",
        "Configure your benchmark run by setting the parameters below:\n",
        "\n",
        "- `execution_mode`: \"openenv\" (REST API) or \"mcp\" (JSON-RPC)\n",
        "- `gym_enviornment_url`: URL of your Gym server\n",
        "- `seed_database_file`: Path to .sql file for database seeding (empty = use gym's api/sample-data)\n",
        "- `system_prompt` & `user_prompt`: Instructions for the AI agent\n",
        "- `llm_model`, `llm_provider`, `llm_api_key`: LLM configuration\n",
        "- `expected_tools`: List of tools the agent should use (optional, for verification)\n",
        "- `restricted_tools`: Tools the agent should NOT use (optional)\n",
        "- `verifiers`: List of verifier configurations to validate agent behavior\n",
        "- `number_of_runs`: How many times to run the benchmark (for statistical analysis)\n",
        "- `reset_database_between_runs`: Whether to reset database between runs (default: true)\n",
        "- `context`: Additional context information passed to Gym server via headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVBcjH1z8E_X"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import asyncio\n",
        "import httpx\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import string\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "from datetime import datetime, timezone\n",
        "from dataclasses import dataclass, asdict\n",
        "from enum import Enum\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "LLM_API_KEY = userdata.get('LLM_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPe7R4X28E_Y",
        "outputId": "ed96a6f8-cca5-43c2-daa9-aac26d9dae26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded\n"
          ]
        }
      ],
      "source": [
        "# BENCHMARK CONFIGURATION (Update The Bellow JSON According to your requinments)\n",
        "CONFIG = {\n",
        "    \"execution_mode\": \"openenv\",  # \"openenv\" or \"mcp\"\n",
        "    \"gym_enviornment_url\": \"https://correspondence-water-sentence-requested.trycloudflare.com\",\n",
        "    \"mcp_endpoint\": \"/mcp\",\n",
        "    \"seed_database_file\": \"/content/seed-db.sql\",  # Path to .sql file (empty = use gym's api/sample-data)\n",
        "    \"llm_provider\": \"openai\",\n",
        "    \"llm_model\": \"gpt-5.2\",\n",
        "    \"llm_api_key\": LLM_API_KEY,\n",
        "    \"temperature\": 0.0,\n",
        "    \"max_tokens\": 4096,\n",
        "    \"system_prompt\": \"You are a Google Calendar automation agent with full administrative permissions to manage users, meetings, recordings, and messages. Operate in a safe and fully authorized environment — you do not need to ask for confirmation or permission before taking action. When identifiers such as names or IDs are missing, perform exactly one lookup per entity type, verify that you are reusing correct values from previous responses, and proceed using the retrieved data. Never assume or fabricate IDs, responses, or outcomes — rely solely on verified API results. Complete each task in a single, logical, and efficient execution flow.\",\n",
        "    \"user_prompt\": \"Help me tidy up my calendars for Q4? First, make sure my Project Management calendar is showing and selected. Then find my \\\"Sprint Planning & Architecture Review\\\" meeting and move the latest one to my main calendar so it's easier to track. Update its description to something like \\\"Updated for Q4 planning with new architecture goals and sprint alignment.\\\"\\nAfter that, add a new event called \\\"Q4 Initiative Kickoff – Engineering & UX\\\" to the Project Management calendar for next Thursday from 10AM-12PM. That should cover everything I need!\",\n",
        "    \"number_of_runs\": 2,\n",
        "    \"reset_database_between_runs\": True,\n",
        "    \"context\": {\n",
        "      \"actingUserId\": \"alice_manager\",\n",
        "      \"actingUserEmail\": \"alice.manager@techcorp.com\",\n",
        "      \"defaultTimeZone\": \"America/New_York\",\n",
        "      \"x-access-token\": \"ya29.A0ARrdaM-k9Vq7GzY2pL4mQf8sN1xT0bR3uHcJWv5yKzP6eF2.qwErTyUIopASDfGhJkLzXcVbNm12_34-56\"\n",
        "    },\n",
        "    \"auth_config\": None,\n",
        "    \"expected_tools\": [\n",
        "        \"get_calendar_list\",\n",
        "        \"list_events\",\n",
        "        \"update_calendar_in_list\",\n",
        "        \"move_event\",\n",
        "        \"patch_event\",\n",
        "        \"create_event\",\n",
        "        \"delete_event\"\n",
        "    ],\n",
        "    \"restricted_tools\": [],\n",
        "    \"verifiers\": [\n",
        "        {\n",
        "            \"verifier_type\": \"database_state\",\n",
        "            \"name\": \"Project Calendar Visible\",\n",
        "            \"description\": \"Ensures Alice's Project Management calendar is visible and selected.\",\n",
        "            \"validation_config\": {\n",
        "                \"query\": \"SELECT COUNT(*) FROM calendars WHERE calendar_id='alice-projects' AND hidden=0 AND selected=1;\",\n",
        "                \"expected_value\": 1,\n",
        "                \"comparison_type\": \"equals\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"verifier_type\": \"database_state\",\n",
        "            \"name\": \"Event Moved to Primary\",\n",
        "            \"description\": \"Checks that the Sprint Planning event is on the primary calendar.\",\n",
        "            \"validation_config\": {\n",
        "                \"query\": \"SELECT COUNT(*) FROM events WHERE event_id='event-corrected-001' AND calendar_id='alice-primary';\",\n",
        "                \"expected_value\": 1,\n",
        "                \"comparison_type\": \"equals\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"verifier_type\": \"database_state\",\n",
        "            \"name\": \"Event Description Updated\",\n",
        "            \"description\": \"Ensures the event description was updated to the new Q4 wording .\",\n",
        "            \"validation_config\": {\n",
        "                \"query\": \"SELECT COUNT(*) FROM events WHERE event_id='event-corrected-001' AND description LIKE '%Q4%' AND description LIKE '%planning%' AND description LIKE '%architecture%' \",\n",
        "                \"expected_value\": 1,\n",
        "                \"comparison_type\": \"equals\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"verifier_type\": \"database_state\",\n",
        "            \"name\": \"Kickoff Event Created\",\n",
        "            \"description\": \"Ensures that the new Q4 kickoff event was created on Project Management.\",\n",
        "            \"validation_config\": {\n",
        "                \"query\": \"SELECT COUNT(*) FROM events WHERE summary='Q4 Initiative Kickoff – Engineering & UX' AND calendar_id='alice-projects' AND start_datetime LIKE '%2026-01-15 10:00%'\\nAND end_datetime LIKE '%2026-01-15 12:00:%'AND status='confirmed'\",\n",
        "                \"expected_value\": 1,\n",
        "                \"comparison_type\": \"equals\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"verifier_type\": \"database_state\",\n",
        "            \"name\": \"Verify Old mapping removed\",\n",
        "            \"description\": \"Verify Old mapping removed\",\n",
        "            \"validation_config\": {\n",
        "                \"query\": \"SELECT COUNT(*) FROM events WHERE event_id='event-corrected-001' AND calendar_id='alice-projects';\",\n",
        "                \"expected_value\": 0,\n",
        "                \"comparison_type\": \"equals\"\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Configuration loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbdPdjX08E_Y"
      },
      "source": [
        "## Complete Implementation\n",
        "\n",
        "The following cell contains the full implementation of all classes and functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LOv7xdE8E_Z"
      },
      "source": [
        "## 3. Data Models\n",
        "\n",
        "Define all data structures and enums used throughout the benchmark system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7DDlwub8E_Z",
        "outputId": "3c1de56a-0b9d-41e7-956d-328a3faea436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data models defined\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# DATA MODELS\n",
        "# ============================================================================\n",
        "\n",
        "class VerifierType(str, Enum):\n",
        "    DATABASE_STATE = \"database_state\"\n",
        "    RESPONSE_CHECKER = \"response_check\"\n",
        "    TOOL_EXECUTION = \"tool_execution\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MCPToolCall:\n",
        "    \"\"\"Represents an MCP tool call\"\"\"\n",
        "    tool_name: str\n",
        "    arguments: Dict[str, Any]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MCPToolResponse:\n",
        "    \"\"\"Represents an MCP tool response\"\"\"\n",
        "    success: bool\n",
        "    result: Any = None\n",
        "    error: Optional[str] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class VerifierConfig:\n",
        "    \"\"\"Configuration for a verifier\"\"\"\n",
        "    verifier_type: str\n",
        "    validation_config: Dict[str, Any]\n",
        "    name: Optional[str] = None\n",
        "    description: Optional[str] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class BenchmarkConfig:\n",
        "    \"\"\"Complete benchmark configuration\"\"\"\n",
        "    gym_enviornment_url: str\n",
        "    mcp_endpoint: str\n",
        "    seed_database_file: str  # Path to .sql file (empty = use gym's api/sample-data)\n",
        "    system_prompt: str\n",
        "    user_prompt: str\n",
        "    llm_model: str\n",
        "    llm_provider: str  # \"anthropic\", \"openai\", \"google\"\n",
        "    llm_api_key: str\n",
        "    verifiers: List[Dict[str, Any]]\n",
        "    number_of_runs: int\n",
        "    context: Dict[str, Any]\n",
        "    execution_mode: str = \"openenv\"  # \"openenv\" or \"mcp\"\n",
        "    expected_tools: Optional[List[str]] = None\n",
        "    restricted_tools: Optional[List[str]] = None\n",
        "    temperature: float = 0.0\n",
        "    max_tokens: int = 4096\n",
        "    reset_database_between_runs: bool = True\n",
        "    auth_config: Optional[Dict[str, Any]] = None\n",
        "\n",
        "print(\"Data models defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xipsolO8E_a"
      },
      "source": [
        "## 4. Database Management Functions\n",
        "\n",
        "Functions for automatically creating and deleting test databases from the Gym server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWtUwkMN8E_a"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DATABASE MANAGEMENT\n",
        "# ============================================================================\n",
        "\n",
        "def create_database_from_file(gym_url: str, sql_file_path: str, config_dir: str = \"\") -> Optional[str]:\n",
        "    \"\"\"Create a new database from a SQL file and return database_id.\"\"\"\n",
        "    try:\n",
        "        # Generate unique database_id\n",
        "        timestamp = int(time.time() * 1000)\n",
        "        suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=9))\n",
        "        database_id = f\"db_{timestamp}_{suffix}\"\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "        # Read SQL file\n",
        "        if not os.path.isabs(sql_file_path):\n",
        "            sql_file_path = os.path.join(config_dir, sql_file_path) if config_dir else sql_file_path\n",
        "\n",
        "        logger.info(f\"Reading SQL file: {sql_file_path}\")\n",
        "        if not os.path.exists(sql_file_path):\n",
        "            logger.error(f\"SQL file not found: {sql_file_path}\")\n",
        "            return None\n",
        "\n",
        "        with open(sql_file_path, 'r', encoding='utf-8') as f:\n",
        "            sql_content = f.read()\n",
        "\n",
        "        logger.info(f\"SQL size: {len(sql_content) / 1024:.2f} KB\")\n",
        "\n",
        "        # Create database\n",
        "        db_name = f\"Auto DB {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        logger.info(f\"Creating database '{db_name}'...\")\n",
        "        payload = {\n",
        "            \"database_id\": database_id,\n",
        "            \"name\": db_name,\n",
        "            \"description\": f\"Created from {os.path.basename(sql_file_path)}\",\n",
        "            \"sql_content\": sql_content\n",
        "        }\n",
        "\n",
        "        timeout = max(120, int(120 + len(sql_content) / 102400))\n",
        "        with httpx.Client(timeout=timeout) as client:\n",
        "            response = client.post(f\"{gym_url}/api/seed-database\", headers=headers, json=payload)\n",
        "            response.raise_for_status()\n",
        "\n",
        "        logger.info(f\"Database created from file: {database_id}\")\n",
        "        return database_id\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating database from file: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_database(gym_url: str) -> Optional[str]:\n",
        "    \"\"\"Create a new database from Gym server sample SQL and return database_id.\"\"\"\n",
        "    try:\n",
        "        # Generate unique database_id\n",
        "        timestamp = int(time.time() * 1000)\n",
        "        suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=9))\n",
        "        database_id = f\"db_{timestamp}_{suffix}\"\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "        # Fetch sample SQL from Gym server\n",
        "        logger.info(f\"Fetching sample SQL from {gym_url}...\")\n",
        "        with httpx.Client(timeout=60) as client:\n",
        "            response = client.get(f\"{gym_url}/api/sample-data\", headers=headers)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if isinstance(data, dict) and 'sql_content' in data:\n",
        "                sql_content = data['sql_content']\n",
        "            elif isinstance(data, dict) and 'text' in data:\n",
        "                sql_content = data['text']\n",
        "            elif isinstance(data, str):\n",
        "                sql_content = data\n",
        "            else:\n",
        "                raise ValueError(f\"Could not extract SQL content from response\")\n",
        "\n",
        "        logger.info(f\"SQL size: {len(sql_content) / 1024:.2f} KB\")\n",
        "\n",
        "        # Create database\n",
        "        db_name = f\"Auto DB {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        logger.info(f\"Creating database '{db_name}'...\")\n",
        "        payload = {\n",
        "            \"database_id\": database_id,\n",
        "            \"name\": db_name,\n",
        "            \"description\": \"Auto-created from Gym server\",\n",
        "            \"sql_content\": sql_content\n",
        "        }\n",
        "\n",
        "        timeout = max(120, int(120 + len(sql_content) / 102400))\n",
        "        with httpx.Client(timeout=timeout) as client:\n",
        "            response = client.post(f\"{gym_url}/api/seed-database\", headers=headers, json=payload)\n",
        "            response.raise_for_status()\n",
        "\n",
        "        logger.info(f\"Database created: {database_id}\")\n",
        "        return database_id\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating database: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def delete_database(gym_url: str, database_id: str) -> bool:\n",
        "    \"\"\"Delete a database from the Gym server.\"\"\"\n",
        "    try:\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        payload = {\"database_id\": database_id}\n",
        "\n",
        "        logger.info(f\"Deleting database: {database_id}...\")\n",
        "\n",
        "        with httpx.Client(timeout=30) as client:\n",
        "            response = client.request(\"DELETE\", f\"{gym_url}/api/delete-database\", headers=headers, json=payload)\n",
        "\n",
        "            # Handle servers that don't have this API\n",
        "            if response.status_code == 404:\n",
        "                logger.warning(f\"Server does not support database deletion API\")\n",
        "                return False\n",
        "            elif response.status_code == 405:\n",
        "                logger.warning(f\"Database deletion not allowed on this server\")\n",
        "                return False\n",
        "\n",
        "            response.raise_for_status()\n",
        "\n",
        "        logger.info(f\"Database deleted successfully\")\n",
        "        return True\n",
        "\n",
        "    except httpx.HTTPStatusError as e:\n",
        "        if e.response.status_code in [404, 405]:\n",
        "            logger.warning(f\"Server does not support database deletion (HTTP {e.response.status_code})\")\n",
        "        else:\n",
        "            logger.error(f\"Error deleting database: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error deleting database: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIkBTwhy8E_b"
      },
      "source": [
        "## 5. Protocol Clients (OpenEnv + MCP)\n",
        "\n",
        "HTTP clients for interacting with both OpenEnv REST API (RFC 002) and MCP JSON-RPC protocol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiKLGXr_8E_b",
        "outputId": "8f86cd18-c174-4ee4-bb1b-279afd3bbf50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Protocol clients (OpenEnv + MCP) defined\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PROTOCOL CLIENTS (OpenEnv REST API + MCP JSON-RPC)\n",
        "# ============================================================================\n",
        "\n",
        "class OpenEnvClient:\n",
        "    \"\"\"\n",
        "    HTTP-based OpenEnv Client for REST API communication with OpenEnv servers.\n",
        "    Uses /reset, /step, and /state endpoints (OpenEnv RFC 002).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_url: str, auth_config: Optional[Dict[str, Any]] = None,\n",
        "                 mcp_endpoint: str = \"/mcp\", database_id: Optional[str] = None,\n",
        "                 context: Optional[Dict[str, Any]] = None, seed_database_file: str = \"\",\n",
        "                 sql_content: Optional[str] = None):\n",
        "        self.base_url = base_url.rstrip(\"/\")\n",
        "        self.database_id = database_id\n",
        "        self.auth_config = auth_config\n",
        "        self.context = context or {}\n",
        "        self.seed_database_file = seed_database_file\n",
        "        self.sql_content = sql_content  # SQL content from seed file\n",
        "        self.timeout = 60.0\n",
        "        self.total_reward = 0.0\n",
        "        self.connected = False\n",
        "\n",
        "    def _headers(self) -> Dict[str, str]:\n",
        "        \"\"\"Get headers for HTTP requests\"\"\"\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"x-database-id\": self.database_id,\n",
        "        }\n",
        "        # Add authentication token if provided\n",
        "        if self.auth_config:\n",
        "            auth_type = self.auth_config.get(\"type\")\n",
        "            token = self.auth_config.get(\"token\")\n",
        "            header_name = self.auth_config.get(\"header_name\", \"Authorization\")\n",
        "\n",
        "            if auth_type == \"bearer\":\n",
        "                headers[header_name] = f\"Bearer {token}\"\n",
        "            elif auth_type == \"api_key\":\n",
        "                headers[header_name] = token\n",
        "\n",
        "        # Add context headers\n",
        "        if self.context and isinstance(self.context, dict):\n",
        "            for key, value in self.context.items():\n",
        "                # Don't add extra \"x-\" if key already starts with \"x-\"\n",
        "                if key.lower().startswith(\"x-\"):\n",
        "                    header_key = key.lower().replace('_', '-')\n",
        "                else:\n",
        "                    header_key = f\"x-{key.lower().replace('_', '-')}\"\n",
        "                headers[header_key] = str(value)\n",
        "\n",
        "        return headers\n",
        "\n",
        "    async def connect(self) -> bool:\n",
        "        \"\"\"Connect to OpenEnv server (no initialization needed for REST API)\"\"\"\n",
        "        try:\n",
        "            # For OpenEnv, we just verify the server is reachable\n",
        "            self.connected = True\n",
        "            logger.info(f\"Connected to OpenEnv server: {self.base_url}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to connect to OpenEnv server: {e}\")\n",
        "            return False\n",
        "\n",
        "    async def reset(self) -> Dict[str, Any]:\n",
        "        \"\"\"Reset environment using OpenEnv /reset endpoint with custom SQL content\"\"\"\n",
        "        logger.info(f\"Resetting {self.base_url} (db: {self.database_id})...\")\n",
        "        try:\n",
        "            # Build request payload\n",
        "            payload = {}\n",
        "\n",
        "            # Add sql_content if available (from user-provided seed file)\n",
        "            if self.sql_content:\n",
        "                payload[\"sql_content\"] = self.sql_content\n",
        "                logger.info(f\"Using custom SQL ({len(self.sql_content) / 1024:.2f} KB)\")\n",
        "\n",
        "            async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "                response = await client.post(\n",
        "                    f\"{self.base_url}/reset\",\n",
        "                    json=payload if payload else None,\n",
        "                    headers=self._headers()\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "                    episode_id = data.get('metadata', {}).get('episode_id', 'N/A')\n",
        "                    logger.info(f\"Reset successful - Episode: {episode_id[:8] if episode_id != 'N/A' else 'N/A'}\")\n",
        "                    self.total_reward = 0.0\n",
        "                    return {\"success\": True, \"data\": data}\n",
        "\n",
        "                # Handle servers that don't support /reset endpoint\n",
        "                if response.status_code == 404:\n",
        "                    logger.warning(\"Server does not support /reset endpoint - continuing without reset\")\n",
        "                    self.total_reward = 0.0\n",
        "                    return {\"success\": True, \"data\": {}, \"fallback\": True}\n",
        "\n",
        "                logger.error(f\"Reset failed: HTTP {response.status_code}\")\n",
        "                return {\"success\": False, \"error\": f\"HTTP {response.status_code}\"}\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Reset failed: {e} - continuing without reset\")\n",
        "            self.total_reward = 0.0\n",
        "            return {\"success\": True, \"data\": {}, \"fallback\": True}\n",
        "\n",
        "    async def list_tools(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"List available tools using OpenEnv /step with ListToolsAction\"\"\"\n",
        "        logger.info(\"Listing tools...\")\n",
        "        try:\n",
        "            async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "                response = await client.post(\n",
        "                    f\"{self.base_url}/step\",\n",
        "                    json={\"action_type\": \"ListToolsAction\"},\n",
        "                    headers=self._headers()\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    tools = response.json().get(\"observation\", {}).get(\"tools_list\", [])\n",
        "                    logger.info(f\"Found {len(tools)} tools\")\n",
        "                    return tools\n",
        "\n",
        "                logger.error(f\"List tools failed: HTTP {response.status_code}\")\n",
        "                return []\n",
        "        except Exception as e:\n",
        "            logger.error(f\"List tools failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    async def call_tool(\n",
        "        self,\n",
        "        tool_name: str,\n",
        "        arguments: Dict[str, Any] = None,\n",
        "        database_id: Optional[str] = None,\n",
        "        context: Optional[Dict[str, Any]] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Execute a tool using OpenEnv /step with ToolCallAction\"\"\"\n",
        "        logger.info(f\"Calling {tool_name}...\")\n",
        "        try:\n",
        "            # Build headers (override instance values if provided)\n",
        "            headers = self._headers()\n",
        "            if database_id:\n",
        "                headers[\"x-database-id\"] = database_id\n",
        "\n",
        "            # Add any additional context headers (these override instance context)\n",
        "            if context and isinstance(context, dict):\n",
        "                for key, value in context.items():\n",
        "                    # Don't add extra \"x-\" if key already starts with \"x-\"\n",
        "                    if key.lower().startswith(\"x-\"):\n",
        "                        header_key = key.lower().replace('_', '-')\n",
        "                    else:\n",
        "                        header_key = f\"x-{key.lower().replace('_', '-')}\"\n",
        "                    headers[header_key] = str(value)\n",
        "\n",
        "            async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "                response = await client.post(\n",
        "                    f\"{self.base_url}/step\",\n",
        "                    json={\n",
        "                        \"action_type\": \"ToolCallAction\",\n",
        "                        \"tool_name\": tool_name,\n",
        "                        \"arguments\": arguments or {}\n",
        "                    },\n",
        "                    headers=headers\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "                    reward = data.get(\"reward\", 0.0)\n",
        "                    self.total_reward += reward\n",
        "                    observation = data.get(\"observation\", {})\n",
        "                    success = observation.get(\"success\", False)\n",
        "                    logger.info(f\"{tool_name} (success={success}, reward={reward})\")\n",
        "                    return {\n",
        "                        \"success\": True,\n",
        "                        \"result\": observation,\n",
        "                        \"reward\": reward\n",
        "                    }\n",
        "\n",
        "                logger.error(f\"Tool call failed: HTTP {response.status_code}\")\n",
        "                return {\"success\": False, \"error\": f\"HTTP {response.status_code}\"}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Tool call failed: {e}\")\n",
        "            return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "    async def reset_database(self, database_id: str = None, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Reset database using OpenEnv /reset endpoint\"\"\"\n",
        "        return await self.reset()\n",
        "\n",
        "    async def get_state(self, verify_queries: Optional[List[str]] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Get current environment state using OpenEnv /state endpoint\"\"\"\n",
        "        logger.info(\"GET /state\")\n",
        "        try:\n",
        "            params = [(\"verify_queries\", q) for q in verify_queries] if verify_queries else []\n",
        "\n",
        "            async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "                response = await client.get(\n",
        "                    f\"{self.base_url}/state\",\n",
        "                    params=params if params else None,\n",
        "                    headers=self._headers()\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    return {\"success\": True, \"data\": response.json()}\n",
        "\n",
        "                logger.error(f\"Get state failed: HTTP {response.status_code}\")\n",
        "                return {\"success\": False, \"error\": f\"HTTP {response.status_code}\"}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Get state failed: {e}\")\n",
        "            return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "\n",
        "class MCPClient:\n",
        "    \"\"\"\n",
        "    MCP (Model Context Protocol) Client for JSON-RPC communication.\n",
        "    Uses /mcp endpoint with JSON-RPC 2.0 protocol.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_url: str, auth_config: Optional[Dict[str, Any]] = None,\n",
        "                 mcp_endpoint: str = \"/mcp\", database_id: Optional[str] = None,\n",
        "                 context: Optional[Dict[str, Any]] = None, seed_database_file: str = \"\",\n",
        "                 sql_content: Optional[str] = None):\n",
        "        self.base_url = base_url.rstrip(\"/\")\n",
        "        self.mcp_endpoint = mcp_endpoint\n",
        "        self.database_id = database_id\n",
        "        self.auth_config = auth_config\n",
        "        self.context = context or {}\n",
        "        self.seed_database_file = seed_database_file\n",
        "        self.sql_content = sql_content  # SQL content from seed file\n",
        "        self.timeout = 60.0\n",
        "        self.session_id = None\n",
        "        self.request_id = 0\n",
        "        self.connected = False\n",
        "\n",
        "    def _next_request_id(self) -> int:\n",
        "        \"\"\"Get next request ID for JSON-RPC\"\"\"\n",
        "        self.request_id += 1\n",
        "        return self.request_id\n",
        "\n",
        "    def _headers(self) -> Dict[str, str]:\n",
        "        \"\"\"Get headers for HTTP requests\"\"\"\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "        if self.session_id:\n",
        "            headers[\"mcp-session-id\"] = self.session_id\n",
        "\n",
        "        if self.database_id:\n",
        "            headers[\"x-database-id\"] = self.database_id\n",
        "\n",
        "        # Add authentication\n",
        "        if self.auth_config:\n",
        "            auth_type = self.auth_config.get(\"type\")\n",
        "            token = self.auth_config.get(\"token\")\n",
        "            header_name = self.auth_config.get(\"header_name\", \"Authorization\")\n",
        "\n",
        "            if auth_type == \"bearer\":\n",
        "                headers[header_name] = f\"Bearer {token}\"\n",
        "            elif auth_type == \"api_key\":\n",
        "                headers[header_name] = token\n",
        "\n",
        "        # Add context headers\n",
        "        if self.context and isinstance(self.context, dict):\n",
        "            for key, value in self.context.items():\n",
        "                # Don't add extra \"x-\" if key already starts with \"x-\"\n",
        "                if key.lower().startswith(\"x-\"):\n",
        "                    header_key = key.lower().replace('_', '-')\n",
        "                else:\n",
        "                    header_key = f\"x-{key.lower().replace('_', '-')}\"\n",
        "                headers[header_key] = str(value)\n",
        "\n",
        "        return headers\n",
        "\n",
        "    async def _send_request(self, method: str, params: Dict[str, Any] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Send JSON-RPC request\"\"\"\n",
        "        payload = {\n",
        "            \"jsonrpc\": \"2.0\",\n",
        "            \"id\": self._next_request_id(),\n",
        "            \"method\": method,\n",
        "            \"params\": params or {}\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "                response = await client.post(\n",
        "                    f\"{self.base_url}{self.mcp_endpoint}\",\n",
        "                    json=payload,\n",
        "                    headers=self._headers()\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "                    if \"error\" in data:\n",
        "                        return {\"success\": False, \"error\": data[\"error\"]}\n",
        "                    return {\"success\": True, \"result\": data.get(\"result\")}\n",
        "\n",
        "                return {\"success\": False, \"error\": f\"HTTP {response.status_code}\"}\n",
        "        except Exception as e:\n",
        "            return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "    async def connect(self) -> bool:\n",
        "        \"\"\"Initialize MCP session\"\"\"\n",
        "        logger.info(f\"Initializing MCP session with {self.base_url}...\")\n",
        "        result = await self._send_request(\"initialize\", {\n",
        "            \"protocolVersion\": \"2024-11-05\",\n",
        "            \"capabilities\": {},\n",
        "            \"clientInfo\": {\"name\": \"benchmark-executor\", \"version\": \"1.0.0\"}\n",
        "        })\n",
        "\n",
        "        if result.get(\"success\"):\n",
        "            # Extract session ID from response if provided\n",
        "            session_info = result.get(\"result\", {})\n",
        "            if isinstance(session_info, dict) and \"sessionId\" in session_info:\n",
        "                self.session_id = session_info[\"sessionId\"]\n",
        "\n",
        "            self.connected = True\n",
        "            logger.info(f\"MCP session initialized\")\n",
        "            return True\n",
        "\n",
        "        logger.error(f\"MCP initialization failed: {result.get('error')}\")\n",
        "        return False\n",
        "\n",
        "    async def reset(self) -> Dict[str, Any]:\n",
        "        \"\"\"Reset environment (no-op for MCP, handled by reset_database)\"\"\"\n",
        "        return {\"success\": True, \"data\": {}}\n",
        "\n",
        "    async def list_tools(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"List available tools via MCP tools/list\"\"\"\n",
        "        logger.info(\"Listing tools via MCP...\")\n",
        "        result = await self._send_request(\"tools/list\")\n",
        "\n",
        "        if result.get(\"success\"):\n",
        "            tools = result.get(\"result\", {}).get(\"tools\", [])\n",
        "            logger.info(f\"Found {len(tools)} tools\")\n",
        "            return tools\n",
        "\n",
        "        logger.error(f\"List tools failed: {result.get('error')}\")\n",
        "        return []\n",
        "\n",
        "    async def call_tool(\n",
        "        self,\n",
        "        tool_name: str,\n",
        "        arguments: Dict[str, Any] = None,\n",
        "        database_id: Optional[str] = None,\n",
        "        context: Optional[Dict[str, Any]] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Execute a tool via MCP tools/call\"\"\"\n",
        "        logger.info(f\"Calling {tool_name} via MCP...\")\n",
        "\n",
        "        # Temporarily override database_id and context if provided\n",
        "        original_db = self.database_id\n",
        "        original_ctx = self.context\n",
        "\n",
        "        if database_id:\n",
        "            self.database_id = database_id\n",
        "        if context:\n",
        "            self.context = {**self.context, **context}\n",
        "\n",
        "        try:\n",
        "            result = await self._send_request(\"tools/call\", {\n",
        "                \"name\": tool_name,\n",
        "                \"arguments\": arguments or {}\n",
        "            })\n",
        "\n",
        "            if result.get(\"success\"):\n",
        "                tool_result = result.get(\"result\", {})\n",
        "                logger.info(f\"{tool_name} completed\")\n",
        "                return {\"success\": True, \"result\": tool_result}\n",
        "\n",
        "            logger.error(f\"Tool call failed: {result.get('error')}\")\n",
        "            return {\"success\": False, \"error\": result.get(\"error\")}\n",
        "        finally:\n",
        "            # Restore original values\n",
        "            self.database_id = original_db\n",
        "            self.context = original_ctx\n",
        "\n",
        "    async def reset_database(self, database_id: str = None, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Reset database using MCP or fallback to /api/seed-database\"\"\"\n",
        "        target_db = database_id or self.database_id\n",
        "        logger.info(f\"Resetting database: {target_db}\")\n",
        "\n",
        "        # Try OpenEnv /reset endpoint first (with sql_content if available)\n",
        "        try:\n",
        "            headers = self._headers()\n",
        "            if database_id:\n",
        "                headers[\"x-database-id\"] = database_id\n",
        "\n",
        "            if context and isinstance(context, dict):\n",
        "                for key, value in context.items():\n",
        "                    # Don't add extra \"x-\" if key already starts with \"x-\"\n",
        "                    if key.lower().startswith(\"x-\"):\n",
        "                        header_key = key.lower().replace('_', '-')\n",
        "                    else:\n",
        "                        header_key = f\"x-{key.lower().replace('_', '-')}\"\n",
        "                    headers[header_key] = str(value)\n",
        "\n",
        "            # Build payload with sql_content if available\n",
        "            payload = {}\n",
        "            if self.sql_content:\n",
        "                payload[\"sql_content\"] = self.sql_content\n",
        "                logger.info(f\"Using custom SQL ({len(self.sql_content) / 1024:.2f} KB)\")\n",
        "\n",
        "            async with httpx.AsyncClient(timeout=self.timeout) as client:\n",
        "                response = await client.post(\n",
        "                    f\"{self.base_url}/reset\",\n",
        "                    json=payload if payload else None,\n",
        "                    headers=headers\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    logger.info(f\"Database reset successful via /reset\")\n",
        "                    return {\"success\": True}\n",
        "        except Exception as e:\n",
        "            logger.debug(f\"OpenEnv /reset not available: {e}\")\n",
        "\n",
        "        # Fallback: Use /api/seed-database endpoint\n",
        "        logger.info(f\"Attempting database reset via /api/seed-database...\")\n",
        "        try:\n",
        "            # Use sql_content if available, otherwise get sample SQL\n",
        "            if self.sql_content:\n",
        "                sql_content = self.sql_content\n",
        "                logger.info(f\"Using custom SQL from seed file\")\n",
        "            else:\n",
        "                async with httpx.AsyncClient(timeout=60) as client:\n",
        "                    response = await client.get(f\"{self.base_url}/api/sample-data\")\n",
        "                    if response.status_code != 200:\n",
        "                        return {\"success\": False, \"error\": \"Failed to fetch sample SQL\"}\n",
        "\n",
        "                    data = response.json()\n",
        "                    sql_content = data.get('sql_content') or data.get('text') or data\n",
        "\n",
        "            # Seed database\n",
        "            async with httpx.AsyncClient(timeout=max(120, int(120 + len(sql_content) / 102400))) as client:\n",
        "                payload = {\n",
        "                    \"database_id\": target_db,\n",
        "                    \"name\": f\"Reset DB {datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "                    \"sql_content\": sql_content\n",
        "                }\n",
        "\n",
        "                response = await client.post(\n",
        "                    f\"{self.base_url}/api/seed-database\",\n",
        "                    json=payload,\n",
        "                    headers={\"Content-Type\": \"application/json\"}\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    logger.info(f\"Database reset successful via /api/seed-database\")\n",
        "                    return {\"success\": True}\n",
        "\n",
        "                return {\"success\": False, \"error\": f\"Seed failed: HTTP {response.status_code}\"}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Database reset failed: {e}\")\n",
        "            return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "    async def get_state(self, verify_queries: Optional[List[str]] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Get state (MCP doesn't have native state endpoint, return empty)\"\"\"\n",
        "        return {\"success\": True, \"data\": {}}\n",
        "\n",
        "print(\"Protocol clients (OpenEnv + MCP) defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1tAD_zA8E_c"
      },
      "source": [
        "## 6. LLM Client\n",
        "\n",
        "Unified LLM interface supporting multiple providers (Anthropic Claude, OpenAI GPT, Google Gemini) with LangChain integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyVp1JiV8E_c"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LLM CLIENT (Unified interface for Anthropic, OpenAI, Google)\n",
        "# ============================================================================\n",
        "\n",
        "class LLMClient:\n",
        "    \"\"\"\n",
        "    Unified LLM client supporting multiple providers.\n",
        "    Uses LangChain for consistent tool calling interface.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, provider: str, model: str, api_key: str,\n",
        "                 temperature: float = 0.0, max_tokens: int = 4096):\n",
        "        self.provider = provider.lower()\n",
        "        self.model = model\n",
        "        self.api_key = api_key\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "        self.llm = None\n",
        "\n",
        "        self._initialize_llm()\n",
        "\n",
        "    def _initialize_llm(self):\n",
        "        \"\"\"Initialize LLM based on provider\"\"\"\n",
        "        try:\n",
        "            if self.provider == \"anthropic\":\n",
        "                from langchain_anthropic import ChatAnthropic\n",
        "                self.llm = ChatAnthropic(\n",
        "                    model=self.model,\n",
        "                    anthropic_api_key=self.api_key,\n",
        "                    temperature=self.temperature,\n",
        "                    max_tokens=self.max_tokens\n",
        "                )\n",
        "            elif self.provider == \"openai\":\n",
        "                from langchain_openai import ChatOpenAI\n",
        "                self.llm = ChatOpenAI(\n",
        "                    model=self.model,\n",
        "                    openai_api_key=self.api_key,\n",
        "                    temperature=self.temperature,\n",
        "                    max_tokens=self.max_tokens\n",
        "                )\n",
        "            elif self.provider == \"google\":\n",
        "                from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "                self.llm = ChatGoogleGenerativeAI(\n",
        "                    model=self.model,\n",
        "                    google_api_key=self.api_key,\n",
        "                    temperature=self.temperature,\n",
        "                    max_tokens=self.max_tokens\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported LLM provider: {self.provider}\")\n",
        "\n",
        "            logger.info(f\"Initialized {self.provider} LLM: {self.model}\")\n",
        "\n",
        "        except ImportError as e:\n",
        "            logger.error(f\"Failed to import LangChain provider for {self.provider}: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _convert_mcp_tools_to_langchain(self, mcp_tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Convert MCP tool definitions to LangChain format, filtering incompatible schemas\"\"\"\n",
        "        langchain_tools = []\n",
        "\n",
        "        for tool in mcp_tools:\n",
        "            input_schema = tool.get(\"inputSchema\", {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "                \"required\": []\n",
        "            })\n",
        "\n",
        "            # Clean schema: remove oneOf, allOf, anyOf at top level (Anthropic doesn't support them)\n",
        "            cleaned_schema = self._clean_json_schema(input_schema)\n",
        "\n",
        "            tool_def = {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": tool[\"name\"],\n",
        "                    \"description\": tool.get(\"description\", \"\"),\n",
        "                    \"parameters\": cleaned_schema\n",
        "                }\n",
        "            }\n",
        "            langchain_tools.append(tool_def)\n",
        "\n",
        "        return langchain_tools\n",
        "\n",
        "    def _clean_json_schema(self, schema: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Clean JSON schema to be compatible with Anthropic API\n",
        "\n",
        "        Removes oneOf, allOf, anyOf at top level and converts to simple object schema.\n",
        "        \"\"\"\n",
        "        if not isinstance(schema, dict):\n",
        "            return {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "                \"required\": []\n",
        "            }\n",
        "\n",
        "        # If schema has oneOf/allOf/anyOf at top level, extract the first valid object schema\n",
        "        if \"oneOf\" in schema:\n",
        "            logger.debug(f\"Schema has oneOf at top level, extracting first object schema\")\n",
        "            for option in schema[\"oneOf\"]:\n",
        "                if isinstance(option, dict) and option.get(\"type\") == \"object\":\n",
        "                    schema = option\n",
        "                    break\n",
        "            else:\n",
        "                # No object schema found, return empty\n",
        "                return {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {},\n",
        "                    \"required\": []\n",
        "                }\n",
        "\n",
        "        if \"allOf\" in schema:\n",
        "            logger.debug(f\"Schema has allOf at top level, merging schemas\")\n",
        "            merged_schema = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "            for sub_schema in schema[\"allOf\"]:\n",
        "                if isinstance(sub_schema, dict):\n",
        "                    if \"properties\" in sub_schema:\n",
        "                        merged_schema[\"properties\"].update(sub_schema[\"properties\"])\n",
        "                    if \"required\" in sub_schema:\n",
        "                        merged_schema[\"required\"].extend(sub_schema[\"required\"])\n",
        "            schema = merged_schema\n",
        "\n",
        "        if \"anyOf\" in schema:\n",
        "            logger.debug(f\"Schema has anyOf at top level, extracting first object schema\")\n",
        "            for option in schema[\"anyOf\"]:\n",
        "                if isinstance(option, dict) and option.get(\"type\") == \"object\":\n",
        "                    schema = option\n",
        "                    break\n",
        "            else:\n",
        "                return {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {},\n",
        "                    \"required\": []\n",
        "                }\n",
        "\n",
        "        # Ensure schema has required fields\n",
        "        if \"type\" not in schema:\n",
        "            schema[\"type\"] = \"object\"\n",
        "\n",
        "        if schema[\"type\"] == \"object\" and \"properties\" not in schema:\n",
        "            schema[\"properties\"] = {}\n",
        "\n",
        "        return schema\n",
        "\n",
        "    async def invoke_with_tools(\n",
        "        self,\n",
        "        messages: List[Any],\n",
        "        tools: List[Dict[str, Any]]\n",
        "    ) -> Any:\n",
        "        \"\"\"Invoke LLM with tools\"\"\"\n",
        "        from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
        "\n",
        "        # Convert MCP tools to LangChain format\n",
        "        langchain_tools = self._convert_mcp_tools_to_langchain(tools)\n",
        "\n",
        "        # Bind tools to LLM\n",
        "        llm_with_tools = self.llm.bind_tools(langchain_tools)\n",
        "\n",
        "        # Invoke\n",
        "        logger.info(f\"Invoking {self.provider} LLM with {len(tools)} tools\")\n",
        "        response = await llm_with_tools.ainvoke(messages)\n",
        "\n",
        "        return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRcKeQTE8E_c"
      },
      "source": [
        "## 7. Verifier Engine\n",
        "\n",
        "Comprehensive verification engine supporting multiple verifier types: database_state (SQL validation), response_check (LLM-as-judge), and tool_execution (tool usage validation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64YSa4aJ8E_c"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VERIFIER ENGINE\n",
        "# ============================================================================\n",
        "\n",
        "class VerifierEngine:\n",
        "    \"\"\"\n",
        "    Verifier engine for validating benchmark results.\n",
        "    Supports: database_state, response_check, tool_execution\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, protocol_client, llm_client: LLMClient, execution_mode: str = \"openenv\"):\n",
        "        self.protocol_client = protocol_client\n",
        "        self.llm_client = llm_client\n",
        "        self.execution_mode = execution_mode\n",
        "\n",
        "    async def execute_verifier(\n",
        "        self,\n",
        "        verifier: VerifierConfig,\n",
        "        model_response: Dict[str, Any],\n",
        "        database_id: str,\n",
        "        context: Optional[Dict[str, Any]] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Execute a single verifier\"\"\"\n",
        "        logger.info(f\"Executing verifier: {verifier.verifier_type}\")\n",
        "\n",
        "        if verifier.verifier_type == \"database_state\":\n",
        "            return await self._execute_database_state_verifier(\n",
        "                verifier.validation_config, database_id, context\n",
        "            )\n",
        "        elif verifier.verifier_type == \"response_check\":\n",
        "            return await self._execute_response_check_verifier(\n",
        "                verifier.validation_config, model_response, database_id, context\n",
        "            )\n",
        "        elif verifier.verifier_type == \"tool_execution\":\n",
        "            return await self._execute_tool_execution_verifier(\n",
        "                verifier.validation_config, model_response\n",
        "            )\n",
        "        else:\n",
        "            return {\n",
        "                \"passed\": False,\n",
        "                \"error\": f\"Unsupported verifier type: {verifier.verifier_type}\"\n",
        "            }\n",
        "\n",
        "    async def _execute_database_state_verifier(\n",
        "        self,\n",
        "        validation_config: Dict[str, Any],\n",
        "        database_id: str,\n",
        "        context: Optional[Dict[str, Any]] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Execute database state verifier\"\"\"\n",
        "        sql_query = validation_config.get(\"query\")\n",
        "        expected_value = validation_config.get(\"expected_value\")\n",
        "        comparison_type = validation_config.get(\"comparison_type\", \"equals\")\n",
        "\n",
        "        if not sql_query:\n",
        "            return {\"passed\": False, \"error\": \"No SQL query provided\"}\n",
        "\n",
        "        logger.info(f\"Executing SQL query: {sql_query}\")\n",
        "\n",
        "        # Execute SQL query via MCP\n",
        "        result = await self._execute_sql_query(sql_query, database_id, context)\n",
        "\n",
        "        if not result[\"success\"]:\n",
        "            return {\n",
        "                \"passed\": False,\n",
        "                \"error\": f\"SQL query failed: {result.get('error')}\",\n",
        "                \"query\": sql_query\n",
        "            }\n",
        "\n",
        "        # Extract value from result\n",
        "        actual_value = self._extract_value_from_sql_result(result)\n",
        "\n",
        "        logger.info(f\"SQL result - Expected: {expected_value}, Actual: {actual_value}\")\n",
        "\n",
        "        # Compare values\n",
        "        comparison_result = self._compare_values(actual_value, expected_value, comparison_type)\n",
        "\n",
        "        return {\n",
        "            \"passed\": comparison_result[\"passed\"],\n",
        "            \"expected\": expected_value,\n",
        "            \"actual\": actual_value,\n",
        "            \"comparison_type\": comparison_type,\n",
        "            \"query\": sql_query,\n",
        "            \"details\": comparison_result.get(\"details\")\n",
        "        }\n",
        "\n",
        "    async def _execute_response_check_verifier(\n",
        "        self,\n",
        "        validation_config: Dict[str, Any],\n",
        "        model_response: Dict[str, Any],\n",
        "        database_id: str,\n",
        "        context: Optional[Dict[str, Any]] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Execute response check verifier using LLM-as-judge\"\"\"\n",
        "        sql_query = validation_config.get(\"sql_query\")\n",
        "        comparison_prompt = validation_config.get(\"comparison_prompt\")\n",
        "        minimum_comparison_value = validation_config.get(\"minimum_comparison_value\", 7)\n",
        "\n",
        "        if not sql_query or not comparison_prompt:\n",
        "            return {\n",
        "                \"passed\": False,\n",
        "                \"error\": \"Missing sql_query or comparison_prompt\"\n",
        "            }\n",
        "\n",
        "        # Execute SQL query\n",
        "        sql_result = await self._execute_sql_query(sql_query, database_id, context)\n",
        "\n",
        "        if not sql_result[\"success\"]:\n",
        "            return {\n",
        "                \"passed\": False,\n",
        "                \"error\": f\"SQL query failed: {sql_result.get('error')}\"\n",
        "            }\n",
        "\n",
        "        # Extract LLM response text\n",
        "        llm_response_text = self._extract_llm_content(model_response)\n",
        "\n",
        "        # Use LLM as judge\n",
        "        judge_result = await self._compare_with_llm(\n",
        "            sql_result,\n",
        "            llm_response_text,\n",
        "            comparison_prompt,\n",
        "            minimum_comparison_value\n",
        "        )\n",
        "\n",
        "        return judge_result\n",
        "\n",
        "    async def _execute_tool_execution_verifier(\n",
        "        self,\n",
        "        validation_config: Dict[str, Any],\n",
        "        model_response: Dict[str, Any]\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Execute tool execution verifier\"\"\"\n",
        "        expected_tools = validation_config.get(\"expected_tools\", [])\n",
        "        minimum_tool_calls = validation_config.get(\"minimum_tool_calls\", 1)\n",
        "\n",
        "        # Extract tools called from model response\n",
        "        tools_called = []\n",
        "        if \"tool_calls\" in model_response and model_response[\"tool_calls\"]:\n",
        "            tools_called = [tc[\"name\"] for tc in model_response[\"tool_calls\"]]\n",
        "\n",
        "        logger.info(f\"Expected tools: {expected_tools}, Called: {tools_called}\")\n",
        "\n",
        "        # Check if expected tools were called\n",
        "        missing_tools = [tool for tool in expected_tools if tool not in tools_called]\n",
        "\n",
        "        # Check minimum tool calls\n",
        "        passed = (\n",
        "            len(missing_tools) == 0 and\n",
        "            len(tools_called) >= minimum_tool_calls\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"passed\": passed,\n",
        "            \"expected_tools\": expected_tools,\n",
        "            \"tools_called\": tools_called,\n",
        "            \"missing_tools\": missing_tools,\n",
        "            \"minimum_tool_calls\": minimum_tool_calls,\n",
        "            \"actual_tool_calls\": len(tools_called)\n",
        "        }\n",
        "\n",
        "    async def _execute_sql_query(\n",
        "        self,\n",
        "        query: str,\n",
        "        database_id: str,\n",
        "        context: Optional[Dict[str, Any]] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Execute SQL query via OpenEnv /state or MCP /api/sql-runner\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Executing SQL query: {query}\")\n",
        "\n",
        "            if self.execution_mode == \"openenv\":\n",
        "                # Use OpenEnv /state endpoint with verify_queries parameter\n",
        "                state_result = await self.protocol_client.get_state(verify_queries=[query])\n",
        "\n",
        "                if not state_result.get(\"success\"):\n",
        "                    return {\n",
        "                        \"success\": False,\n",
        "                        \"error\": state_result.get(\"error\", \"State query failed\")\n",
        "                    }\n",
        "\n",
        "                # Extract verification result\n",
        "                state_data = state_result.get(\"data\", {})\n",
        "                verification_results = state_data.get(\"verification_results\", [])\n",
        "\n",
        "                if not verification_results or len(verification_results) == 0:\n",
        "                    return {\n",
        "                        \"success\": False,\n",
        "                        \"error\": \"No verification results returned from /state\"\n",
        "                    }\n",
        "\n",
        "                # Get the first (and only) verification result\n",
        "                query_result = verification_results[0]\n",
        "\n",
        "                # Check if query itself failed\n",
        "                if \"error\" in query_result:\n",
        "                    return {\n",
        "                        \"success\": False,\n",
        "                        \"error\": query_result.get(\"error\", \"Query execution failed\")\n",
        "                    }\n",
        "\n",
        "                # Return the query result\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"result\": query_result.get(\"result\", [])\n",
        "                }\n",
        "\n",
        "            else:  # MCP mode\n",
        "                # Use direct HTTP call to /api/sql-runner endpoint\n",
        "                headers = {\n",
        "                    \"Content-Type\": \"application/json\",\n",
        "                    \"x-database-id\": database_id\n",
        "                }\n",
        "\n",
        "                # Add context headers\n",
        "                if context and isinstance(context, dict):\n",
        "                    for key, value in context.items():\n",
        "                        header_key = f\"x-{key.lower().replace('_', '-')}\"\n",
        "                        headers[header_key] = str(value)\n",
        "\n",
        "                # Add session ID if available\n",
        "                if hasattr(self.protocol_client, 'session_id') and self.protocol_client.session_id:\n",
        "                    headers[\"mcp-session-id\"] = self.protocol_client.session_id\n",
        "\n",
        "                payload = {\"query\": query}\n",
        "\n",
        "                async with httpx.AsyncClient(timeout=30.0) as client:\n",
        "                    response = await client.post(\n",
        "                        f\"{self.protocol_client.base_url}/api/sql-runner\",\n",
        "                        json=payload,\n",
        "                        headers=headers\n",
        "                    )\n",
        "\n",
        "                    if response.status_code == 200:\n",
        "                        result_data = response.json()\n",
        "                        return {\"success\": True, \"result\": result_data}\n",
        "\n",
        "                    return {\n",
        "                        \"success\": False,\n",
        "                        \"error\": f\"SQL runner failed: HTTP {response.status_code}\"\n",
        "                    }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"SQL query execution failed: {e}\")\n",
        "            return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "    def _extract_value_from_sql_result(self, result: dict) -> Any:\n",
        "        \"\"\"Extract the actual value from SQL query result (matches production implementation)\"\"\"\n",
        "        if not result:\n",
        "            return None\n",
        "\n",
        "        # If the result itself is not successful, check for error content\n",
        "        if not result.get(\"success\"):\n",
        "            # Try to extract error message from MCP response format\n",
        "            result_data = result.get(\"result\", {})\n",
        "            if isinstance(result_data, dict) and \"content\" in result_data:\n",
        "                content = result_data[\"content\"]\n",
        "                if isinstance(content, list) and len(content) > 0:\n",
        "                    for item in content:\n",
        "                        if isinstance(item, dict) and item.get(\"type\") == \"text\":\n",
        "                            return item.get(\"text\", \"Error\")\n",
        "            return None\n",
        "\n",
        "        result_data = result.get(\"result\", {})\n",
        "\n",
        "        # Handle OpenEnv format: result is directly a list like [{'count': 1}]\n",
        "        if isinstance(result_data, list):\n",
        "            if len(result_data) > 0:\n",
        "                # If single row with single column, return the value directly\n",
        "                if len(result_data) == 1 and isinstance(result_data[0], dict) and len(result_data[0]) == 1:\n",
        "                    return list(result_data[0].values())[0]\n",
        "                # If single row with multiple columns, return the row dict\n",
        "                elif len(result_data) == 1:\n",
        "                    return result_data[0]\n",
        "                # Multiple rows, return the full result\n",
        "                else:\n",
        "                    return result_data\n",
        "            return result_data\n",
        "\n",
        "        # Handle different result formats from MCP sql-runner\n",
        "        if isinstance(result_data, dict):\n",
        "            # If result has 'data' field (common format)\n",
        "            if \"data\" in result_data:\n",
        "                data = result_data[\"data\"]\n",
        "                if isinstance(data, list) and len(data) > 0:\n",
        "                    # If single row with single column, return the value directly\n",
        "                    if len(data) == 1 and isinstance(data[0], dict) and len(data[0]) == 1:\n",
        "                        return list(data[0].values())[0]\n",
        "                    # If single row with multiple columns, return the row dict\n",
        "                    elif len(data) == 1:\n",
        "                        return data[0]\n",
        "                    # Multiple rows, return the full result\n",
        "                    else:\n",
        "                        return data\n",
        "                return data\n",
        "\n",
        "            # If result has 'rows' field\n",
        "            elif \"rows\" in result_data:\n",
        "                rows = result_data[\"rows\"]\n",
        "                if isinstance(rows, list) and len(rows) > 0:\n",
        "                    # Single value from single row\n",
        "                    if len(rows) == 1 and isinstance(rows[0], dict) and len(rows[0]) == 1:\n",
        "                        return list(rows[0].values())[0]\n",
        "                    # Single row as list\n",
        "                    elif len(rows) == 1 and isinstance(rows[0], list) and len(rows[0]) == 1:\n",
        "                        return rows[0][0]\n",
        "                    # Single row (dict or list)\n",
        "                    elif len(rows) == 1:\n",
        "                        return rows[0]\n",
        "                    # Multiple rows\n",
        "                    else:\n",
        "                        return rows\n",
        "                return rows\n",
        "\n",
        "            # If result has 'content' field (MCP error format)\n",
        "            elif \"content\" in result_data:\n",
        "                content = result_data[\"content\"]\n",
        "                if isinstance(content, list) and len(content) > 0:\n",
        "                    # Extract text from content array\n",
        "                    for item in content:\n",
        "                        if isinstance(item, dict) and item.get(\"type\") == \"text\":\n",
        "                            return item.get(\"text\", result_data)\n",
        "                return content\n",
        "\n",
        "            # Direct result format (nested 'result' field)\n",
        "            elif \"result\" in result_data:\n",
        "                return result_data[\"result\"]\n",
        "\n",
        "        # Return as-is if we can't extract anything specific\n",
        "        return result_data\n",
        "\n",
        "    def _compare_values(\n",
        "        self,\n",
        "        actual: Any,\n",
        "        expected: Any,\n",
        "        comparison_type: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Compare actual vs expected values\"\"\"\n",
        "        try:\n",
        "            if comparison_type == \"equals\":\n",
        "                passed = actual == expected\n",
        "            elif comparison_type == \"greater_than\":\n",
        "                passed = actual > expected\n",
        "            elif comparison_type == \"less_than\":\n",
        "                passed = actual < expected\n",
        "            elif comparison_type == \"contains\":\n",
        "                passed = expected in str(actual)\n",
        "            else:\n",
        "                return {\n",
        "                    \"passed\": False,\n",
        "                    \"details\": f\"Unknown comparison type: {comparison_type}\"\n",
        "                }\n",
        "\n",
        "            return {\n",
        "                \"passed\": passed,\n",
        "                \"details\": f\"Comparison {comparison_type}: {actual} vs {expected}\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"passed\": False,\n",
        "                \"details\": f\"Comparison error: {e}\"\n",
        "            }\n",
        "\n",
        "    def _extract_llm_content(self, model_response: Dict[str, Any]) -> str:\n",
        "        \"\"\"Extract text content from LLM response\"\"\"\n",
        "        if \"content\" in model_response:\n",
        "            return str(model_response[\"content\"])\n",
        "        elif \"text\" in model_response:\n",
        "            return str(model_response[\"text\"])\n",
        "        elif \"response\" in model_response:\n",
        "            return str(model_response[\"response\"])\n",
        "\n",
        "        return str(model_response)\n",
        "\n",
        "    async def _compare_with_llm(\n",
        "        self,\n",
        "        sql_result: Dict[str, Any],\n",
        "        llm_response: str,\n",
        "        comparison_prompt: str,\n",
        "        minimum_score: int\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Use LLM as judge to compare SQL result with LLM response\"\"\"\n",
        "        from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "        # Build judge prompt\n",
        "        system_prompt = \"\"\"You are an AI judge evaluating the quality and accuracy of an AI assistant's response.\n",
        "Compare the database query result with the AI's response and rate how well they match.\n",
        "Provide a score from 1-10 where:\n",
        "- 1-3: Poor match, incorrect or missing information\n",
        "- 4-6: Partial match, some correct information\n",
        "- 7-8: Good match, mostly correct\n",
        "- 9-10: Excellent match, fully accurate\n",
        "\n",
        "Respond with ONLY a JSON object in this format:\n",
        "{\n",
        "  \"score\": <number 1-10>,\n",
        "  \"reasoning\": \"<brief explanation>\"\n",
        "}\"\"\"\n",
        "\n",
        "        sql_result_str = json.dumps(sql_result.get(\"result\", {}), indent=2)\n",
        "\n",
        "        user_prompt = f\"\"\"Database Query Result:\n",
        "{sql_result_str}\n",
        "\n",
        "AI Assistant Response:\n",
        "{llm_response}\n",
        "\n",
        "Comparison Task:\n",
        "{comparison_prompt}\n",
        "\n",
        "Please provide your judgment as JSON.\"\"\"\n",
        "\n",
        "        messages = [\n",
        "            SystemMessage(content=system_prompt),\n",
        "            HumanMessage(content=user_prompt)\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            response = await self.llm_client.llm.ainvoke(messages)\n",
        "            response_text = response.content\n",
        "\n",
        "            # Parse JSON response\n",
        "            # Try to extract JSON from markdown code blocks\n",
        "            if \"```json\" in response_text:\n",
        "                response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in response_text:\n",
        "                response_text = response_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            judge_result = json.loads(response_text)\n",
        "            score = judge_result.get(\"score\", 0)\n",
        "            reasoning = judge_result.get(\"reasoning\", \"\")\n",
        "\n",
        "            passed = score >= minimum_score\n",
        "\n",
        "            return {\n",
        "                \"passed\": passed,\n",
        "                \"score\": score,\n",
        "                \"minimum_score\": minimum_score,\n",
        "                \"reasoning\": reasoning,\n",
        "                \"sql_result\": sql_result_str,\n",
        "                \"llm_response\": llm_response\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"LLM judge comparison failed: {e}\")\n",
        "            return {\n",
        "                \"passed\": False,\n",
        "                \"error\": f\"Judge comparison failed: {e}\"\n",
        "            }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb5-Pnvk8E_d"
      },
      "source": [
        "## 8. Benchmark Executor\n",
        "\n",
        "Main orchestration engine that coordinates the entire benchmark execution: environment setup, LLM invocation, tool execution, and verification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk3J_sgL8E_d"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BENCHMARK EXECUTOR\n",
        "# ============================================================================\n",
        "\n",
        "class BenchmarkExecutor:\n",
        "    \"\"\"\n",
        "    Main benchmark executor that orchestrates the complete flow:\n",
        "    1. Load tools from OpenEnv server\n",
        "    2. Send prompts to LLM\n",
        "    3. Execute tool calls via OpenEnv /step\n",
        "    4. Loop until completion\n",
        "    5. Run verifiers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: BenchmarkConfig):\n",
        "        self.config = config\n",
        "        self.protocol_client = None\n",
        "        self.llm_client = None\n",
        "        self.verifier_engine = None\n",
        "        self.available_tools = []\n",
        "        self.auto_created_database = False  # Track if we created the database\n",
        "        self.execution_mode = config.execution_mode if hasattr(config, 'execution_mode') else \"openenv\"\n",
        "\n",
        "    async def initialize(self):\n",
        "        \"\"\"Initialize all clients\"\"\"\n",
        "        logger.info(f\"Initializing benchmark executor in {self.execution_mode.upper()} mode...\")\n",
        "\n",
        "        # Initialize protocol client based on execution mode\n",
        "        if self.execution_mode == \"openenv\":\n",
        "            self.protocol_client = OpenEnvClient(\n",
        "                self.config.gym_enviornment_url,\n",
        "                auth_config=self.config.auth_config,\n",
        "                mcp_endpoint=self.config.mcp_endpoint,\n",
        "                database_id=self.config.database_id,\n",
        "                context=self.config.context,\n",
        "                seed_database_file=self.config.seed_database_file\n",
        "            )\n",
        "        else:  # mcp mode\n",
        "            self.protocol_client = MCPClient(\n",
        "                self.config.gym_enviornment_url,\n",
        "                auth_config=self.config.auth_config,\n",
        "                mcp_endpoint=self.config.mcp_endpoint,\n",
        "                database_id=self.config.database_id,\n",
        "                context=self.config.context,\n",
        "                seed_database_file=self.config.seed_database_file\n",
        "            )\n",
        "\n",
        "        connected = await self.protocol_client.connect()\n",
        "        if not connected:\n",
        "            raise Exception(f\"Failed to connect to {self.execution_mode.upper()} server\")\n",
        "\n",
        "        # Reset the environment\n",
        "        reset_result = await self.protocol_client.reset()\n",
        "        if not reset_result.get(\"success\") and not reset_result.get(\"fallback\"):\n",
        "            logger.warning(\"Failed to reset environment, continuing anyway\")\n",
        "\n",
        "        # Load available tools\n",
        "        self.available_tools = await self.protocol_client.list_tools()\n",
        "        logger.info(f\"Loaded {len(self.available_tools)} tools from {self.execution_mode.upper()} server\")\n",
        "\n",
        "        # Apply tool restrictions if configured\n",
        "        if self.config.restricted_tools:\n",
        "            self.available_tools = [\n",
        "                tool for tool in self.available_tools\n",
        "                if tool[\"name\"] not in self.config.restricted_tools\n",
        "            ]\n",
        "            logger.info(f\"Applied tool restrictions. {len(self.available_tools)} tools available\")\n",
        "\n",
        "        # Initialize LLM client\n",
        "        self.llm_client = LLMClient(\n",
        "            self.config.llm_provider,\n",
        "            self.config.llm_model,\n",
        "            self.config.llm_api_key,\n",
        "            temperature=self.config.temperature,\n",
        "            max_tokens=self.config.max_tokens\n",
        "        )\n",
        "\n",
        "        # Initialize verifier engine\n",
        "        self.verifier_engine = VerifierEngine(\n",
        "            self.protocol_client,\n",
        "            self.llm_client,\n",
        "            self.execution_mode\n",
        "        )\n",
        "\n",
        "        logger.info(\"Initialization complete\")\n",
        "\n",
        "    async def execute_single_run(self, run_number: int) -> Dict[str, Any]:\n",
        "        \"\"\"Execute a single benchmark run\"\"\"\n",
        "        logger.info(f\"\\n{'='*80}\")\n",
        "        logger.info(f\"STARTING RUN {run_number}/{self.config.number_of_runs}\")\n",
        "        logger.info(f\"{'='*80}\\n\")\n",
        "\n",
        "        start_time = datetime.now(timezone.utc)\n",
        "\n",
        "        # Reset database if configured\n",
        "        if run_number > 1 and self.config.reset_database_between_runs:\n",
        "            logger.info(\"Resetting environment between runs...\")\n",
        "            # database_id and context are already set in protocol_client\n",
        "            await self.protocol_client.reset()\n",
        "\n",
        "        # Execute the main task (LLM + tool calling loop)\n",
        "        task_result = await self._execute_task()\n",
        "\n",
        "        # Run verifiers\n",
        "        verification_results = await self._run_verifiers(task_result)\n",
        "\n",
        "        # Calculate execution time\n",
        "        execution_time_ms = int((datetime.now(timezone.utc) - start_time).total_seconds() * 1000)\n",
        "\n",
        "        # Determine overall success\n",
        "        overall_success = all(\n",
        "            v[\"passed\"] for v in verification_results.values()\n",
        "        )\n",
        "\n",
        "        # Calculate verification summary\n",
        "        total_verifiers = len(verification_results)\n",
        "        passed_verifiers = sum(1 for v in verification_results.values() if v.get(\"passed\", False))\n",
        "        failed_verifiers = total_verifiers - passed_verifiers\n",
        "\n",
        "        result = {\n",
        "            \"run_number\": run_number,\n",
        "            \"started_at\": start_time.isoformat(),\n",
        "            \"execution_time_ms\": execution_time_ms,\n",
        "            \"model_response\": task_result.get(\"final_response\"),\n",
        "            \"conversation_flow\": task_result.get(\"conversation_flow\", []),\n",
        "            \"tools_used\": task_result.get(\"tools_used\", []),\n",
        "            \"tool_results\": task_result.get(\"tool_results\", []),\n",
        "            \"verification_results\": verification_results,\n",
        "            \"verification_summary\": {\n",
        "                \"total\": total_verifiers,\n",
        "                \"passed\": passed_verifiers,\n",
        "                \"failed\": failed_verifiers,\n",
        "                \"pass_rate\": passed_verifiers / total_verifiers if total_verifiers > 0 else 0.0\n",
        "            },\n",
        "            \"overall_success\": overall_success\n",
        "        }\n",
        "\n",
        "        logger.info(f\"\\nRUN {run_number} COMPLETED\")\n",
        "        logger.info(f\"Verification: {passed_verifiers}/{total_verifiers} passed ({passed_verifiers/total_verifiers*100:.1f}%)\")\n",
        "        logger.info(f\"Overall Success: {overall_success}\")\n",
        "        logger.info(f\"Execution time: {execution_time_ms}ms\")\n",
        "        logger.info(f\"Tools used: {', '.join(task_result.get('tools_used', []))}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    async def _execute_task(self) -> Dict[str, Any]:\n",
        "        \"\"\"Execute the main task with LLM + tool calling loop\"\"\"\n",
        "        from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
        "\n",
        "        # Build initial messages\n",
        "        messages = [\n",
        "            SystemMessage(content=self.config.system_prompt),\n",
        "            HumanMessage(content=self.config.user_prompt)\n",
        "        ]\n",
        "\n",
        "        conversation_flow = []\n",
        "        tools_used = []\n",
        "        tool_results = []\n",
        "        max_iterations = 20  # Prevent infinite loops\n",
        "\n",
        "        for iteration in range(max_iterations):\n",
        "            logger.info(f\"\\n--- Iteration {iteration + 1} ---\")\n",
        "\n",
        "            # Invoke LLM with tools\n",
        "            response = await self.llm_client.invoke_with_tools(\n",
        "                messages,\n",
        "                self.available_tools\n",
        "            )\n",
        "\n",
        "            # Add AI response to conversation\n",
        "            messages.append(response)\n",
        "            conversation_flow.append({\n",
        "                \"type\": \"ai_message\",\n",
        "                \"content\": response.content,\n",
        "                \"tool_calls\": [\n",
        "                    {\n",
        "                        \"name\": tc[\"name\"],\n",
        "                        \"args\": tc[\"args\"]\n",
        "                    }\n",
        "                    for tc in (response.tool_calls or [])\n",
        "                ]\n",
        "            })\n",
        "\n",
        "            logger.info(f\"LLM Response: {response.content}\")\n",
        "\n",
        "            # Check if LLM wants to call tools\n",
        "            if not response.tool_calls or len(response.tool_calls) == 0:\n",
        "                logger.info(\"No tool calls requested. Task complete.\")\n",
        "                break\n",
        "\n",
        "            # Execute tool calls\n",
        "            for tool_call in response.tool_calls:\n",
        "                tool_name = tool_call[\"name\"]\n",
        "                tool_args = tool_call[\"args\"]\n",
        "\n",
        "                logger.info(f\"Executing tool: {tool_name}\")\n",
        "                logger.debug(f\"Tool arguments: {tool_args}\")\n",
        "\n",
        "                # Execute tool via protocol client (database_id and context already set in client)\n",
        "                tool_result = await self.protocol_client.call_tool(\n",
        "                    tool_name,\n",
        "                    tool_args\n",
        "                )\n",
        "\n",
        "                logger.info(f\"Tool result success: {tool_result.get('success')}\")\n",
        "\n",
        "                # Track tools used\n",
        "                if tool_name not in tools_used:\n",
        "                    tools_used.append(tool_name)\n",
        "\n",
        "                tool_results.append({\n",
        "                    \"tool_name\": tool_name,\n",
        "                    \"arguments\": tool_args,\n",
        "                    \"result\": tool_result\n",
        "                })\n",
        "\n",
        "                # Add tool result to conversation\n",
        "                tool_message = ToolMessage(\n",
        "                    content=json.dumps(tool_result.get(\"result\", {})),\n",
        "                    tool_call_id=tool_call.get(\"id\", \"\")\n",
        "                )\n",
        "                messages.append(tool_message)\n",
        "\n",
        "                conversation_flow.append({\n",
        "                    \"type\": \"tool_result\",\n",
        "                    \"tool_name\": tool_name,\n",
        "                    \"result\": tool_result\n",
        "                })\n",
        "\n",
        "        return {\n",
        "            \"final_response\": messages[-1].content if messages else \"\",\n",
        "            \"conversation_flow\": conversation_flow,\n",
        "            \"tools_used\": tools_used,\n",
        "            \"tool_results\": tool_results,\n",
        "            \"messages\": messages\n",
        "        }\n",
        "\n",
        "    async def _run_verifiers(self, task_result: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Run all configured verifiers\"\"\"\n",
        "        logger.info(\"\\n--- Running Verifiers ---\")\n",
        "\n",
        "        verification_results = {}\n",
        "\n",
        "        for i, verifier_config in enumerate(self.config.verifiers):\n",
        "            verifier = VerifierConfig(**verifier_config)\n",
        "            verifier_name = verifier.name or f\"verifier_{i+1}\"\n",
        "\n",
        "            logger.info(f\"Running verifier: {verifier_name} ({verifier.verifier_type})\")\n",
        "\n",
        "            model_response = {\n",
        "                \"content\": task_result.get(\"final_response\", \"\"),\n",
        "                \"tool_calls\": [\n",
        "                    {\"name\": tr[\"tool_name\"], \"args\": tr[\"arguments\"]}\n",
        "                    for tr in task_result.get(\"tool_results\", [])\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            result = await self.verifier_engine.execute_verifier(\n",
        "                verifier,\n",
        "                model_response,\n",
        "                self.config.database_id,\n",
        "                self.config.context\n",
        "            )\n",
        "\n",
        "            verification_results[verifier_name] = result\n",
        "\n",
        "            logger.info(f\"Verifier result: {'PASSED' if result.get('passed') else 'FAILED'}\")\n",
        "            if not result.get(\"passed\"):\n",
        "                logger.warning(f\"Failure reason: {result.get('error') or result.get('details')}\")\n",
        "\n",
        "        return verification_results\n",
        "\n",
        "    async def execute_benchmark(self) -> Dict[str, Any]:\n",
        "        \"\"\"Execute complete benchmark with multiple runs\"\"\"\n",
        "        logger.info(f\"\\n{'='*80}\")\n",
        "        logger.info(f\"STARTING BENCHMARK EXECUTION\")\n",
        "        logger.info(f\"Mode: {self.execution_mode.upper()}\")\n",
        "        logger.info(f\"Model: {self.config.llm_provider}/{self.config.llm_model}\")\n",
        "        logger.info(f\"Number of runs: {self.config.number_of_runs}\")\n",
        "        logger.info(f\"{'='*80}\\n\")\n",
        "\n",
        "        # Create database: use seed_database_file if provided, otherwise use gym's api/sample-data\n",
        "        seed_file = self.config.seed_database_file\n",
        "        sql_content = None  # Will store SQL content for resets\n",
        "\n",
        "        if seed_file and seed_file.strip():\n",
        "            # Use custom SQL file\n",
        "            logger.info(f\"Using seed database file: {seed_file}\")\n",
        "            config_dir = os.path.dirname(os.path.abspath(\"config.json\")) if os.path.exists(\"config.json\") else \"\"\n",
        "            created_db_id = create_database_from_file(\n",
        "                self.config.gym_enviornment_url,\n",
        "                seed_file,\n",
        "                config_dir\n",
        "            )\n",
        "\n",
        "            # Read and store SQL content for reset operations\n",
        "            sql_file_path = seed_file if os.path.isabs(seed_file) else os.path.join(config_dir, seed_file)\n",
        "            if os.path.exists(sql_file_path):\n",
        "                with open(sql_file_path, 'r', encoding='utf-8') as f:\n",
        "                    sql_content = f.read()\n",
        "        else:\n",
        "            # Use gym's api/sample-data\n",
        "            logger.info(\"Using gym's api/sample-data for database creation...\")\n",
        "            created_db_id = create_database(self.config.gym_enviornment_url)\n",
        "\n",
        "        if created_db_id:\n",
        "            self.config.database_id = created_db_id\n",
        "            self.auto_created_database = True\n",
        "            logger.info(f\"Using database: {created_db_id}\")\n",
        "        else:\n",
        "            logger.error(\"Failed to create database. Cannot proceed.\")\n",
        "            raise RuntimeError(\"Database creation failed\")\n",
        "\n",
        "        try:\n",
        "            # Update initialize() to pass sql_content to protocol clients\n",
        "            await self.initialize()\n",
        "\n",
        "            # Store sql_content in protocol_client for resets\n",
        "            if sql_content and self.protocol_client:\n",
        "                self.protocol_client.sql_content = sql_content\n",
        "\n",
        "            # Reset already done in initialize(), but log it\n",
        "            logger.info(\"Environment initialized and reset\")\n",
        "\n",
        "            all_runs = []\n",
        "\n",
        "            for run_number in range(1, self.config.number_of_runs + 1):\n",
        "                try:\n",
        "                    run_result = await self.execute_single_run(run_number)\n",
        "                    all_runs.append(run_result)\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Run {run_number} failed with error: {e}\")\n",
        "                    all_runs.append({\n",
        "                        \"run_number\": run_number,\n",
        "                        \"error\": str(e),\n",
        "                        \"overall_success\": False\n",
        "                    })\n",
        "\n",
        "            # Calculate statistics\n",
        "            statistics = self._calculate_statistics(all_runs)\n",
        "\n",
        "            result = {\n",
        "                \"benchmark_config\": {\n",
        "                    \"execution_mode\": self.execution_mode,\n",
        "                    \"model\": f\"{self.config.llm_provider}/{self.config.llm_model}\",\n",
        "                    \"number_of_runs\": self.config.number_of_runs,\n",
        "                    \"user_prompt\": self.config.user_prompt,\n",
        "                    \"database_id\": self.config.database_id,\n",
        "                    \"seed_database_file\": seed_file or \"(gym's api/sample-data)\",\n",
        "                    \"auto_created_database\": self.auto_created_database\n",
        "                },\n",
        "                \"runs\": all_runs,\n",
        "                \"statistics\": statistics\n",
        "            }\n",
        "\n",
        "            logger.info(f\"\\n{'='*80}\")\n",
        "            logger.info(f\"BENCHMARK COMPLETED\")\n",
        "            logger.info(f\"Overall Success Rate: {statistics['overall_success_rate']:.1%} ({statistics['successful_runs']}/{statistics['total_runs']} runs)\")\n",
        "            logger.info(f\"Verifier Pass Rate: {statistics['verifier_level_pass_rate']:.1%} ({statistics['total_verifiers_passed']}/{statistics['total_verifiers_checked']} verifiers)\")\n",
        "            logger.info(f\"Pass@1: {statistics['pass_at_1']:.1%}\")\n",
        "            logger.info(f\"Mean execution time: {statistics['mean_execution_time_ms']:.0f}ms\")\n",
        "            logger.info(f\"\\nIndividual Verifier Statistics:\")\n",
        "            for verifier_name, stats in statistics.get('individual_verifier_stats', {}).items():\n",
        "                logger.info(f\"  - {verifier_name}: {stats['pass_rate']:.1%} ({stats['passed']}/{stats['total']})\")\n",
        "            logger.info(f\"{'='*80}\\n\")\n",
        "\n",
        "            return result\n",
        "\n",
        "        finally:\n",
        "            # Cleanup: Delete auto-created database\n",
        "            if self.auto_created_database and self.config.database_id:\n",
        "                logger.info(f\"\\nCleaning up auto-created database...\")\n",
        "                print(\"DATABASE_ID: \", self.config.database_id)\n",
        "                # delete_database(self.config.gym_enviornment_url, self.config.database_id)\n",
        "\n",
        "    def _calculate_statistics(self, runs: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate benchmark statistics\"\"\"\n",
        "        successful_runs = [r for r in runs if r.get(\"overall_success\")]\n",
        "        total_runs = len(runs)\n",
        "\n",
        "        # Overall success rate (all verifiers must pass)\n",
        "        overall_success_rate = len(successful_runs) / total_runs if total_runs > 0 else 0\n",
        "\n",
        "        # Pass@1: success on first run\n",
        "        pass_at_1 = 1.0 if runs and runs[0].get(\"overall_success\") else 0.0\n",
        "\n",
        "        # Verifier-level statistics\n",
        "        total_verifiers_count = 0\n",
        "        passed_verifiers_count = 0\n",
        "        verifier_pass_rates = {}\n",
        "\n",
        "        for run in runs:\n",
        "            if \"verification_summary\" in run:\n",
        "                total_verifiers_count += run[\"verification_summary\"][\"total\"]\n",
        "                passed_verifiers_count += run[\"verification_summary\"][\"passed\"]\n",
        "\n",
        "            # Track individual verifier pass rates\n",
        "            for verifier_name, result in run.get(\"verification_results\", {}).items():\n",
        "                if verifier_name not in verifier_pass_rates:\n",
        "                    verifier_pass_rates[verifier_name] = {\"passed\": 0, \"total\": 0}\n",
        "                verifier_pass_rates[verifier_name][\"total\"] += 1\n",
        "                if result.get(\"passed\", False):\n",
        "                    verifier_pass_rates[verifier_name][\"passed\"] += 1\n",
        "\n",
        "        # Calculate pass rate for each verifier\n",
        "        verifier_stats = {}\n",
        "        for verifier_name, counts in verifier_pass_rates.items():\n",
        "            verifier_stats[verifier_name] = {\n",
        "                \"passed\": counts[\"passed\"],\n",
        "                \"total\": counts[\"total\"],\n",
        "                \"pass_rate\": counts[\"passed\"] / counts[\"total\"] if counts[\"total\"] > 0 else 0.0\n",
        "            }\n",
        "\n",
        "        # Overall verifier pass rate\n",
        "        verifier_level_pass_rate = passed_verifiers_count / total_verifiers_count if total_verifiers_count > 0 else 0\n",
        "\n",
        "        # Mean execution time\n",
        "        execution_times = [\n",
        "            r.get(\"execution_time_ms\", 0)\n",
        "            for r in runs\n",
        "            if \"execution_time_ms\" in r\n",
        "        ]\n",
        "        mean_time = sum(execution_times) / len(execution_times) if execution_times else 0\n",
        "\n",
        "        # Tool usage\n",
        "        all_tools = []\n",
        "        for run in runs:\n",
        "            all_tools.extend(run.get(\"tools_used\", []))\n",
        "\n",
        "        tool_counts = {}\n",
        "        for tool in all_tools:\n",
        "            tool_counts[tool] = tool_counts.get(tool, 0) + 1\n",
        "\n",
        "        return {\n",
        "            \"total_runs\": total_runs,\n",
        "            \"successful_runs\": len(successful_runs),\n",
        "            \"overall_success_rate\": overall_success_rate,\n",
        "            \"pass_at_1\": pass_at_1,\n",
        "            \"verifier_level_pass_rate\": verifier_level_pass_rate,\n",
        "            \"total_verifiers_checked\": total_verifiers_count,\n",
        "            \"total_verifiers_passed\": passed_verifiers_count,\n",
        "            \"individual_verifier_stats\": verifier_stats,\n",
        "            \"mean_execution_time_ms\": mean_time,\n",
        "            \"tool_usage\": tool_counts\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N29yaxV58E_e"
      },
      "source": [
        "## 9. Configuration Loader & Main Execution\n",
        "\n",
        "Configuration loading utility and main execution function to run the complete benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piBZa5Cz8E_e",
        "outputId": "76dba87a-9004-45b4-886b-4d80e80df02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loader and main function ready\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION LOADER\n",
        "# ============================================================================\n",
        "\n",
        "def load_config_from_dict(config_dict: Dict[str, Any]) -> BenchmarkConfig:\n",
        "    \"\"\"Load configuration from CONFIG dictionary (no external file needed)\"\"\"\n",
        "    try:\n",
        "        config_data = config_dict.copy()\n",
        "\n",
        "        # Remove comment fields (any key starting with underscore)\n",
        "        config_data = {k: v for k, v in config_data.items() if not k.startswith(\"_\")}\n",
        "\n",
        "        # Clean verifiers - remove _description fields\n",
        "        if \"verifiers\" in config_data and config_data[\"verifiers\"]:\n",
        "            cleaned_verifiers = []\n",
        "            for verifier in config_data[\"verifiers\"]:\n",
        "                cleaned_verifier = {k: v for k, v in verifier.items() if not k.startswith(\"_\")}\n",
        "                cleaned_verifiers.append(cleaned_verifier)\n",
        "            config_data[\"verifiers\"] = cleaned_verifiers\n",
        "\n",
        "        # Validate required fields\n",
        "        required_fields = [\n",
        "            \"gym_enviornment_url\",\n",
        "            \"seed_database_file\",\n",
        "            \"system_prompt\",\n",
        "            \"user_prompt\",\n",
        "            \"llm_model\",\n",
        "            \"llm_provider\",\n",
        "            \"llm_api_key\"\n",
        "        ]\n",
        "\n",
        "        for field in required_fields:\n",
        "            if field not in config_data:\n",
        "                raise ValueError(f\"Missing required field in CONFIG: {field}\")\n",
        "\n",
        "        # Set defaults\n",
        "        config_data.setdefault(\"mcp_endpoint\", \"/mcp\")\n",
        "        config_data.setdefault(\"verifiers\", [])\n",
        "        config_data.setdefault(\"number_of_runs\", 1)\n",
        "        config_data.setdefault(\"context\", {})\n",
        "        config_data.setdefault(\"temperature\", 0.0)\n",
        "        config_data.setdefault(\"max_tokens\", 4096)\n",
        "        config_data.setdefault(\"reset_database_between_runs\", True)\n",
        "        config_data.setdefault(\"execution_mode\", \"openenv\")\n",
        "\n",
        "        # Validate execution_mode\n",
        "        if config_data[\"execution_mode\"] not in [\"openenv\", \"mcp\"]:\n",
        "            raise ValueError(f\"Invalid execution_mode: {config_data['execution_mode']}. Must be 'openenv' or 'mcp'\")\n",
        "\n",
        "        return BenchmarkConfig(**config_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load configuration: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN ENTRY POINT (Uses CONFIG from cell 5)\n",
        "# ============================================================================\n",
        "\n",
        "async def main(config_dict: Dict[str, Any] = None):\n",
        "    \"\"\"Main entry point - uses CONFIG dictionary from notebook\"\"\"\n",
        "    try:\n",
        "        # Use provided config_dict or expect CONFIG to be defined globally\n",
        "        if config_dict is None:\n",
        "            if 'CONFIG' not in globals():\n",
        "                raise ValueError(\"CONFIG dictionary not found. Please define it in cell 5.\")\n",
        "            config_dict = CONFIG\n",
        "\n",
        "        # Load configuration from dictionary\n",
        "        config = load_config_from_dict(config_dict)\n",
        "\n",
        "        # Create executor\n",
        "        executor = BenchmarkExecutor(config)\n",
        "\n",
        "        # Execute benchmark\n",
        "        result = await executor.execute_benchmark()\n",
        "\n",
        "        # Save results to file\n",
        "        output_file = f\"benchmark_results_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(result, f, indent=2, default=str)\n",
        "\n",
        "        logger.info(f\"\\nResults saved to: {output_file}\")\n",
        "\n",
        "        # Print summary\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"BENCHMARK SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"Execution Mode: {result['benchmark_config']['execution_mode'].upper()}\")\n",
        "        print(f\"Model: {result['benchmark_config']['model']}\")\n",
        "        print(f\"Runs: {result['statistics']['total_runs']}\")\n",
        "        print(f\"Overall Success Rate: {result['statistics']['overall_success_rate']:.1%} ({result['statistics']['successful_runs']}/{result['statistics']['total_runs']} runs)\")\n",
        "        print(f\"Verifier Pass Rate: {result['statistics']['verifier_level_pass_rate']:.1%} ({result['statistics']['total_verifiers_passed']}/{result['statistics']['total_verifiers_checked']} verifiers)\")\n",
        "        print(f\"Pass@1: {result['statistics']['pass_at_1']:.1%}\")\n",
        "        print(f\"Mean Execution Time: {result['statistics']['mean_execution_time_ms']:.0f}ms\")\n",
        "        print(\"\\nIndividual Verifier Statistics:\")\n",
        "        for verifier_name, stats in result['statistics'].get('individual_verifier_stats', {}).items():\n",
        "            print(f\"  - {verifier_name}: {stats['pass_rate']:.1%} ({stats['passed']}/{stats['total']})\")\n",
        "        print(\"\\nTool Usage:\")\n",
        "        for tool, count in result['statistics']['tool_usage'].items():\n",
        "            print(f\"  - {tool}: {count} calls\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Benchmark execution failed: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "print(\"Configuration loader and main function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JErjQF6m8E_e"
      },
      "source": [
        "## Execute Benchmark\n",
        "\n",
        "Run the cell below to execute the benchmark with your configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Wg8rQh6U8E_e",
        "outputId": "627845f6-ba42-477a-8b3b-8a3b2738f537"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:__main__:Failure reason: Comparison equals: 0 vs 1\n",
            "WARNING:__main__:Failure reason: Comparison equals: 0 vs 1\n",
            "WARNING:__main__:Failure reason: Comparison equals: 0 vs 1\n",
            "WARNING:__main__:Failure reason: Comparison equals: 0 vs 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATABASE_ID:  db_1769535944605_7a0xldyiq\n",
            "\n",
            "================================================================================\n",
            "BENCHMARK SUMMARY\n",
            "================================================================================\n",
            "Execution Mode: OPENENV\n",
            "Model: openai/gpt-5.2\n",
            "Runs: 2\n",
            "Overall Success Rate: 0.0% (0/2 runs)\n",
            "Verifier Pass Rate: 60.0% (6/10 verifiers)\n",
            "Pass@1: 0.0%\n",
            "Mean Execution Time: 20168ms\n",
            "\n",
            "Individual Verifier Statistics:\n",
            "  - Project Calendar Visible: 100.0% (2/2)\n",
            "  - Event Moved to Primary: 50.0% (1/2)\n",
            "  - Event Description Updated: 50.0% (1/2)\n",
            "  - Kickoff Event Created: 0.0% (0/2)\n",
            "  - Verify Old mapping removed: 100.0% (2/2)\n",
            "\n",
            "Tool Usage:\n",
            "  - get_calendar_list: 2 calls\n",
            "  - update_calendar_in_list: 1 calls\n",
            "  - list_events: 1 calls\n",
            "  - move_event: 1 calls\n",
            "  - patch_event: 1 calls\n",
            "  - create_event: 1 calls\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'benchmark_config': {'execution_mode': 'openenv',\n",
              "  'model': 'openai/gpt-5.2',\n",
              "  'number_of_runs': 2,\n",
              "  'user_prompt': 'Help me tidy up my calendars for Q4? First, make sure my Project Management calendar is showing and selected. Then find my \"Sprint Planning & Architecture Review\" meeting and move the latest one to my main calendar so it\\'s easier to track. Update its description to something like \"Updated for Q4 planning with new architecture goals and sprint alignment.\"\\nAfter that, add a new event called \"Q4 Initiative Kickoff – Engineering & UX\" to the Project Management calendar for next Thursday from 10AM-12PM. That should cover everything I need!',\n",
              "  'database_id': 'db_1769535944605_7a0xldyiq',\n",
              "  'seed_database_file': '/content/seed-db.sql',\n",
              "  'auto_created_database': True},\n",
              " 'runs': [{'run_number': 1,\n",
              "   'started_at': '2026-01-27T17:45:46.615589+00:00',\n",
              "   'execution_time_ms': 23452,\n",
              "   'model_response': '- **Project Management calendar**: confirmed it’s **visible and selected** (Calendar ID: `alice-projects`).\\n- **Moved latest “Sprint Planning & Architecture Review”**: moved event `event-corrected-001` from **Project Management** → **Main (primary) calendar** (`alice-primary`), and updated the description to:  \\n  **“Updated for Q4 planning with new architecture goals and sprint alignment.”**\\n- **Created new event** on **Project Management** calendar:\\n  - **Title:** Q4 Initiative Kickoff – Engineering & UX\\n  - **When:** **Thu, Jan 29, 2026, 10:00 AM – 12:00 PM** (America/New_York)\\n  - **Event ID:** `d4a790ae-eddb-41f2-ae65-b8c5c5234978`',\n",
              "   'conversation_flow': [{'type': 'ai_message',\n",
              "     'content': '',\n",
              "     'tool_calls': [{'name': 'get_calendar_list', 'args': {}}]},\n",
              "    {'type': 'tool_result',\n",
              "     'tool_name': 'get_calendar_list',\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 2,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'get_calendar_list',\n",
              "        'arguments': {}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#calendarList\",\\n  \"etag\": \"etag-list-db_1769535944605_7a0xldyiq\",\\n  \"nextPageToken\": null,\\n  \"nextSyncToken\": \"MjAyNi0wMS0yN1QxNzo0NTo0OS4xMzg3NTU=\",\\n  \"items\": [\\n    {\\n      \"kind\": \"calendar#calendarListEntry\",\\n      \"etag\": \"etag-list-alice-primary-2026-01-27T17:45:45\",\\n      \"id\": \"alice-primary\",\\n      \"summary\": \"Alice Johnson\",\\n      \"description\": \"Primary calendar for Alice Johnson - Project Manager\",\\n      \"location\": null,\\n      \"timeZone\": \"America/New_York\",\\n      \"summaryOverride\": null,\\n      \"colorId\": \"1\",\\n      \"backgroundColor\": null,\\n      \"foregroundColor\": null,\\n      \"hidden\": false,\\n      \"selected\": true,\\n      \"accessRole\": \"owner\",\\n      \"defaultReminders\": null,\\n      \"notificationSettings\": null,\\n      \"primary\": true,\\n      \"deleted\": false,\\n      \"conferenceProperties\": {\\n        \"allowedConferenceSolutionTypes\": []\\n      }\\n    },\\n    {\\n      \"kind\": \"calendar#calendarListEntry\",\\n      \"etag\": \"etag-list-alice-projects-2026-01-27T17:45:45\",\\n      \"id\": \"alice-projects\",\\n      \"summary\": \"Project Management\",\\n      \"description\": \"Project meetings, deadlines, and milestones\",\\n      \"location\": null,\\n      \"timeZone\": \"America/New_York\",\\n      \"summaryOverride\": null,\\n      \"colorId\": \"7\",\\n      \"backgroundColor\": null,\\n      \"foregroundColor\": null,\\n      \"hidden\": false,\\n      \"selected\": true,\\n      \"accessRole\": \"owner\",\\n      \"defaultReminders\": null,\\n      \"notificationSettings\": null,\\n      \"primary\": false,\\n      \"deleted\": false,\\n      \"conferenceProperties\": {\\n        \"allowedConferenceSolutionTypes\": []\\n      }\\n    },\\n    {\\n      \"kind\": \"calendar#calendarListEntry\",\\n      \"etag\": \"etag-list-alice-team-2026-01-27T17:45:45\",\\n      \"id\": \"alice-team\",\\n      \"summary\": \"Team Coordination\",\\n      \"description\": \"Team meetings, 1-on-1s, and team events\",\\n      \"location\": null,\\n      \"timeZone\": \"America/New_York\",\\n      \"summaryOverride\": null,\\n      \"colorId\": \"11\",\\n      \"backgroundColor\": null,\\n      \"foregroundColor\": null,\\n      \"hidden\": false,\\n      \"selected\": true,\\n      \"accessRole\": \"owner\",\\n      \"defaultReminders\": null,\\n      \"notificationSettings\": null,\\n      \"primary\": false,\\n      \"deleted\": false,\\n      \"conferenceProperties\": {\\n        \"allowedConferenceSolutionTypes\": []\\n      }\\n    }\\n  ]\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'type': 'ai_message',\n",
              "     'content': '',\n",
              "     'tool_calls': [{'name': 'update_calendar_in_list',\n",
              "       'args': {'calendarId': 'alice-projects',\n",
              "        'hidden': False,\n",
              "        'selected': True}},\n",
              "      {'name': 'list_events',\n",
              "       'args': {'calendarId': 'alice-projects',\n",
              "        'q': 'Sprint Planning & Architecture Review',\n",
              "        'singleEvents': True,\n",
              "        'orderBy': 'startTime',\n",
              "        'timeMin': '2025-01-27T00:00:00-05:00',\n",
              "        'timeMax': '2026-12-31T23:59:59-05:00',\n",
              "        'maxResults': 2500}}]},\n",
              "    {'type': 'tool_result',\n",
              "     'tool_name': 'update_calendar_in_list',\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 3,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'update_calendar_in_list',\n",
              "        'arguments': {'calendarId': 'alice-projects',\n",
              "         'hidden': False,\n",
              "         'selected': True}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#calendarListEntry\",\\n  \"etag\": \"etag-list-alice-projects-2026-01-27T17:45:45\",\\n  \"id\": \"alice-projects\",\\n  \"summary\": \"Project Management\",\\n  \"description\": \"Project meetings, deadlines, and milestones\",\\n  \"location\": null,\\n  \"timeZone\": \"America/New_York\",\\n  \"summaryOverride\": null,\\n  \"colorId\": \"7\",\\n  \"backgroundColor\": null,\\n  \"foregroundColor\": null,\\n  \"hidden\": false,\\n  \"selected\": true,\\n  \"accessRole\": \"owner\",\\n  \"defaultReminders\": null,\\n  \"notificationSettings\": null,\\n  \"primary\": false,\\n  \"deleted\": false,\\n  \"conferenceProperties\": {\\n    \"allowedConferenceSolutionTypes\": []\\n  }\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'type': 'tool_result',\n",
              "     'tool_name': 'list_events',\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 4,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'list_events',\n",
              "        'arguments': {'calendarId': 'alice-projects',\n",
              "         'q': 'Sprint Planning & Architecture Review',\n",
              "         'singleEvents': True,\n",
              "         'orderBy': 'startTime',\n",
              "         'timeMin': '2025-01-27T00:00:00-05:00',\n",
              "         'timeMax': '2026-12-31T23:59:59-05:00',\n",
              "         'maxResults': 2500}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#events\",\\n  \"etag\": \"etag-events-alice-projects\",\\n  \"summary\": \"Project Management\",\\n  \"description\": \"Project meetings, deadlines, and milestones\",\\n  \"updated\": \"2026-01-27T17:45:54.715123+00:00\",\\n  \"timeZone\": \"America/New_York\",\\n  \"accessRole\": \"owner\",\\n  \"defaultReminders\": [],\\n  \"nextPageToken\": null,\\n  \"nextSyncToken\": null,\\n  \"items\": [\\n    {\\n      \"kind\": \"calendar#event\",\\n      \"etag\": \"\\\\\"1769516145.0\\\\\"\",\\n      \"id\": \"event-corrected-001\",\\n      \"status\": \"confirmed\",\\n      \"htmlLink\": \"https://calendar.google.com/event?eid=event-corrected-001\",\\n      \"created\": \"2026-01-27T17:45:45\",\\n      \"updated\": \"2026-01-27T17:45:45\",\\n      \"summary\": \"Sprint Planning & Architecture Review\",\\n      \"description\": \"Detailed sprint planning session with architecture discussion for Q4 features. We\\'ll review user stories, estimate effort, and plan the technical approach.\",\\n      \"location\": \"Conference Room A, Building 1\",\\n      \"colorId\": \"7\",\\n      \"creator\": {\\n        \"id\": \"alice_manager\",\\n        \"email\": \"alice.johnson@techcorp.com\",\\n        \"displayName\": \"Alice Johnson\",\\n        \"self\": true\\n      },\\n      \"organizer\": {\\n        \"id\": \"alice_manager\",\\n        \"email\": \"alice.johnson@techcorp.com\",\\n        \"displayName\": \"Alice Johnson\",\\n        \"self\": true\\n      },\\n      \"start\": {\\n        \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n        \"date\": null,\\n        \"timeZone\": \"America/New_York\"\\n      },\\n      \"end\": {\\n        \"dateTime\": \"2026-01-27T11:00:00+00:00\",\\n        \"date\": null,\\n        \"timeZone\": \"America/New_York\"\\n      },\\n      \"endTimeUnspecified\": false,\\n      \"recurrence\": [],\\n      \"recurringEventId\": \"NULL\",\\n      \"originalStartTime\": {\\n        \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n        \"date\": null,\\n        \"timeZone\": \"America/New_York\"\\n      },\\n      \"transparency\": null,\\n      \"visibility\": \"default\",\\n      \"iCalUID\": \"event-corrected-001@gmail.com\",\\n      \"sequence\": 1,\\n      \"attendees\": [\\n        {\\n          \"id\": \"att-corrected-001\",\\n          \"email\": \"alice.manager@techcorp.com\",\\n          \"displayName\": \"Alice Johnson\",\\n          \"self\": false,\\n          \"organizer\": false,\\n          \"responseStatus\": \"accepted\",\\n          \"comment\": \"Looking forward to planning Q4!\",\\n          \"additionalGuests\": 0,\\n          \"optional\": false,\\n          \"resource\": false\\n        },\\n        {\\n          \"id\": \"att-corrected-002\",\\n          \"email\": \"bob.smith@techcorp.com\",\\n          \"displayName\": \"Bob Smith\",\\n          \"self\": false,\\n          \"organizer\": false,\\n          \"responseStatus\": \"accepted\",\\n          \"comment\": null,\\n          \"additionalGuests\": 0,\\n          \"optional\": false,\\n          \"resource\": false\\n        },\\n        {\\n          \"id\": \"att-corrected-003\",\\n          \"email\": \"carol.white@techcorp.com\",\\n          \"displayName\": \"Carol White\",\\n          \"self\": false,\\n          \"organizer\": false,\\n          \"responseStatus\": \"tentative\",\\n          \"comment\": \"Will join if no conflicts with user research session\",\\n          \"additionalGuests\": 0,\\n          \"optional\": true,\\n          \"resource\": false\\n        },\\n        {\\n          \"id\": \"att-corrected-004\",\\n          \"email\": null,\\n          \"displayName\": \"Conference Room A\",\\n          \"self\": false,\\n          \"organizer\": false,\\n          \"responseStatus\": \"accepted\",\\n          \"comment\": null,\\n          \"additionalGuests\": 0,\\n          \"optional\": false,\\n          \"resource\": true\\n        }\\n      ],\\n      \"attendeesOmitted\": false,\\n      \"extendedProperties\": {\\n        \"private\": {\\n          \"departmentBudget\": \"engineering\",\\n          \"projectCode\": \"PROJ-2024-Q4\"\\n        },\\n        \"shared\": {\\n          \"meetingType\": \"sprint_planning\",\\n          \"priority\": \"high\"\\n        }\\n      },\\n      \"hangoutLink\": null,\\n      \"conferenceData\": {\\n        \"conferenceSolution\": {\\n          \"iconUri\": null,\\n          \"key\": {\\n            \"type\": \"hangoutsMeet\"\\n          },\\n          \"name\": null\\n        },\\n        \"createRequest\": {\\n          \"conferenceSolutionKey\": null,\\n          \"requestId\": \"req-sprint-planning-001\",\\n          \"status\": {\\n            \"statusCode\": \"success\"\\n          }\\n        },\\n        \"entryPoints\": [\\n          {\\n            \"accessCode\": null,\\n            \"entryPointType\": \"video\",\\n            \"label\": null,\\n            \"meetingCode\": null,\\n            \"passcode\": null,\\n            \"password\": null,\\n            \"pin\": null,\\n            \"uri\": \"https://meet.google.com/abc-defg-hij\"\\n          }\\n        ],\\n        \"notes\": null,\\n        \"signature\": null\\n      },\\n      \"guestsCanInviteOthers\": true,\\n      \"guestsCanModify\": false,\\n      \"guestsCanSeeOtherGuests\": true,\\n      \"privateCopy\": null,\\n      \"locked\": null,\\n      \"reminders\": {\\n        \"overrides\": [\\n          {\\n            \"method\": \"email\",\\n            \"minutes\": 1440\\n          },\\n          {\\n            \"method\": \"popup\",\\n            \"minutes\": 30\\n          }\\n        ],\\n        \"useDefault\": false\\n      },\\n      \"source\": {\\n        \"url\": \"https://jira.techcorp.com/sprint-planning-q4\",\\n        \"title\": \"Sprint Planning Board\"\\n      },\\n      \"attachments\": [\\n        {\\n          \"fileUrl\": \"https://drive.google.com/file/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/view\",\\n          \"title\": \"view\"\\n        },\\n        {\\n          \"fileUrl\": \"https://docs.google.com/spreadsheets/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/edit\",\\n          \"title\": \"edit\"\\n        }\\n      ],\\n      \"eventType\": \"default\",\\n      \"birthdayProperties\": null,\\n      \"focusTimeProperties\": null,\\n      \"outOfOfficeProperties\": null,\\n      \"workingLocationProperties\": null\\n    }\\n  ]\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'type': 'ai_message',\n",
              "     'content': '',\n",
              "     'tool_calls': [{'name': 'move_event',\n",
              "       'args': {'calendarId': 'alice-projects',\n",
              "        'eventId': 'event-corrected-001',\n",
              "        'destination': 'alice-primary',\n",
              "        'sendUpdates': 'all'}}]},\n",
              "    {'type': 'tool_result',\n",
              "     'tool_name': 'move_event',\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 5,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'move_event',\n",
              "        'arguments': {'calendarId': 'alice-projects',\n",
              "         'eventId': 'event-corrected-001',\n",
              "         'destination': 'alice-primary',\n",
              "         'sendUpdates': 'all'}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#event\",\\n  \"etag\": \"\\\\\"1769516157.58162\\\\\"\",\\n  \"id\": \"event-corrected-001\",\\n  \"status\": \"confirmed\",\\n  \"htmlLink\": \"https://calendar.google.com/event?eid=event-corrected-001\",\\n  \"created\": \"2026-01-27T17:45:45\",\\n  \"updated\": \"2026-01-27T17:45:57.581620\",\\n  \"summary\": \"Sprint Planning & Architecture Review\",\\n  \"description\": \"Detailed sprint planning session with architecture discussion for Q4 features. We\\'ll review user stories, estimate effort, and plan the technical approach.\",\\n  \"location\": \"Conference Room A, Building 1\",\\n  \"colorId\": \"7\",\\n  \"creator\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.johnson@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"organizer\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.johnson@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"start\": {\\n    \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"end\": {\\n    \"dateTime\": \"2026-01-27T11:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"endTimeUnspecified\": false,\\n  \"recurrence\": [],\\n  \"recurringEventId\": \"NULL\",\\n  \"originalStartTime\": {\\n    \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"transparency\": null,\\n  \"visibility\": \"default\",\\n  \"iCalUID\": \"event-corrected-001@gmail.com\",\\n  \"sequence\": 1,\\n  \"attendees\": [\\n    {\\n      \"id\": \"att-corrected-001\",\\n      \"email\": \"alice.manager@techcorp.com\",\\n      \"displayName\": \"Alice Johnson\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": \"Looking forward to planning Q4!\",\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-002\",\\n      \"email\": \"bob.smith@techcorp.com\",\\n      \"displayName\": \"Bob Smith\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": null,\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-003\",\\n      \"email\": \"carol.white@techcorp.com\",\\n      \"displayName\": \"Carol White\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"tentative\",\\n      \"comment\": \"Will join if no conflicts with user research session\",\\n      \"additionalGuests\": 0,\\n      \"optional\": true,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-004\",\\n      \"email\": null,\\n      \"displayName\": \"Conference Room A\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": null,\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": true\\n    }\\n  ],\\n  \"attendeesOmitted\": false,\\n  \"extendedProperties\": {\\n    \"private\": {\\n      \"departmentBudget\": \"engineering\",\\n      \"projectCode\": \"PROJ-2024-Q4\"\\n    },\\n    \"shared\": {\\n      \"meetingType\": \"sprint_planning\",\\n      \"priority\": \"high\"\\n    }\\n  },\\n  \"hangoutLink\": null,\\n  \"conferenceData\": {\\n    \"conferenceSolution\": {\\n      \"iconUri\": null,\\n      \"key\": {\\n        \"type\": \"hangoutsMeet\"\\n      },\\n      \"name\": null\\n    },\\n    \"createRequest\": {\\n      \"conferenceSolutionKey\": null,\\n      \"requestId\": \"req-sprint-planning-001\",\\n      \"status\": {\\n        \"statusCode\": \"success\"\\n      }\\n    },\\n    \"entryPoints\": [\\n      {\\n        \"accessCode\": null,\\n        \"entryPointType\": \"video\",\\n        \"label\": null,\\n        \"meetingCode\": null,\\n        \"passcode\": null,\\n        \"password\": null,\\n        \"pin\": null,\\n        \"uri\": \"https://meet.google.com/abc-defg-hij\"\\n      }\\n    ],\\n    \"notes\": null,\\n    \"signature\": null\\n  },\\n  \"guestsCanInviteOthers\": true,\\n  \"guestsCanModify\": false,\\n  \"guestsCanSeeOtherGuests\": true,\\n  \"privateCopy\": null,\\n  \"locked\": null,\\n  \"reminders\": {\\n    \"overrides\": [\\n      {\\n        \"method\": \"email\",\\n        \"minutes\": 1440\\n      },\\n      {\\n        \"method\": \"popup\",\\n        \"minutes\": 30\\n      }\\n    ],\\n    \"useDefault\": false\\n  },\\n  \"source\": {\\n    \"url\": \"https://jira.techcorp.com/sprint-planning-q4\",\\n    \"title\": \"Sprint Planning Board\"\\n  },\\n  \"attachments\": [\\n    {\\n      \"fileUrl\": \"https://drive.google.com/file/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/view\",\\n      \"title\": \"view\"\\n    },\\n    {\\n      \"fileUrl\": \"https://docs.google.com/spreadsheets/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/edit\",\\n      \"title\": \"edit\"\\n    }\\n  ],\\n  \"eventType\": \"default\",\\n  \"birthdayProperties\": null,\\n  \"focusTimeProperties\": null,\\n  \"outOfOfficeProperties\": null,\\n  \"workingLocationProperties\": null\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'type': 'ai_message',\n",
              "     'content': '',\n",
              "     'tool_calls': [{'name': 'patch_event',\n",
              "       'args': {'calendarId': 'alice-primary',\n",
              "        'eventId': 'event-corrected-001',\n",
              "        'description': 'Updated for Q4 planning with new architecture goals and sprint alignment.',\n",
              "        'sendUpdates': 'all'}}]},\n",
              "    {'type': 'tool_result',\n",
              "     'tool_name': 'patch_event',\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 6,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'patch_event',\n",
              "        'arguments': {'calendarId': 'alice-primary',\n",
              "         'eventId': 'event-corrected-001',\n",
              "         'description': 'Updated for Q4 planning with new architecture goals and sprint alignment.',\n",
              "         'sendUpdates': 'all'}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#event\",\\n  \"etag\": \"\\\\\"1769516160.36052\\\\\"\",\\n  \"id\": \"event-corrected-001\",\\n  \"status\": \"confirmed\",\\n  \"htmlLink\": \"https://calendar.google.com/event?eid=event-corrected-001\",\\n  \"created\": \"2026-01-27T17:45:45\",\\n  \"updated\": \"2026-01-27T17:46:00.360520\",\\n  \"summary\": \"Sprint Planning & Architecture Review\",\\n  \"description\": \"Updated for Q4 planning with new architecture goals and sprint alignment.\",\\n  \"location\": \"Conference Room A, Building 1\",\\n  \"colorId\": \"7\",\\n  \"creator\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.johnson@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"organizer\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.johnson@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"start\": {\\n    \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"end\": {\\n    \"dateTime\": \"2026-01-27T11:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"endTimeUnspecified\": false,\\n  \"recurrence\": [],\\n  \"recurringEventId\": \"NULL\",\\n  \"originalStartTime\": {\\n    \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"transparency\": null,\\n  \"visibility\": \"default\",\\n  \"iCalUID\": \"event-corrected-001@gmail.com\",\\n  \"sequence\": 2,\\n  \"attendees\": [\\n    {\\n      \"id\": \"att-corrected-001\",\\n      \"email\": \"alice.manager@techcorp.com\",\\n      \"displayName\": \"Alice Johnson\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": \"Looking forward to planning Q4!\",\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-002\",\\n      \"email\": \"bob.smith@techcorp.com\",\\n      \"displayName\": \"Bob Smith\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": null,\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-003\",\\n      \"email\": \"carol.white@techcorp.com\",\\n      \"displayName\": \"Carol White\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"tentative\",\\n      \"comment\": \"Will join if no conflicts with user research session\",\\n      \"additionalGuests\": 0,\\n      \"optional\": true,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-004\",\\n      \"email\": null,\\n      \"displayName\": \"Conference Room A\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": null,\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": true\\n    }\\n  ],\\n  \"attendeesOmitted\": false,\\n  \"extendedProperties\": {\\n    \"private\": {\\n      \"departmentBudget\": \"engineering\",\\n      \"projectCode\": \"PROJ-2024-Q4\"\\n    },\\n    \"shared\": {\\n      \"meetingType\": \"sprint_planning\",\\n      \"priority\": \"high\"\\n    }\\n  },\\n  \"hangoutLink\": null,\\n  \"conferenceData\": {\\n    \"conferenceSolution\": {\\n      \"iconUri\": null,\\n      \"key\": {\\n        \"type\": \"hangoutsMeet\"\\n      },\\n      \"name\": null\\n    },\\n    \"createRequest\": {\\n      \"conferenceSolutionKey\": null,\\n      \"requestId\": \"req-sprint-planning-001\",\\n      \"status\": {\\n        \"statusCode\": \"success\"\\n      }\\n    },\\n    \"entryPoints\": [\\n      {\\n        \"accessCode\": null,\\n        \"entryPointType\": \"video\",\\n        \"label\": null,\\n        \"meetingCode\": null,\\n        \"passcode\": null,\\n        \"password\": null,\\n        \"pin\": null,\\n        \"uri\": \"https://meet.google.com/abc-defg-hij\"\\n      }\\n    ],\\n    \"notes\": null,\\n    \"signature\": null\\n  },\\n  \"guestsCanInviteOthers\": true,\\n  \"guestsCanModify\": false,\\n  \"guestsCanSeeOtherGuests\": true,\\n  \"privateCopy\": null,\\n  \"locked\": null,\\n  \"reminders\": {\\n    \"overrides\": [\\n      {\\n        \"method\": \"email\",\\n        \"minutes\": 1440\\n      },\\n      {\\n        \"method\": \"popup\",\\n        \"minutes\": 30\\n      }\\n    ],\\n    \"useDefault\": false\\n  },\\n  \"source\": {\\n    \"url\": \"https://jira.techcorp.com/sprint-planning-q4\",\\n    \"title\": \"Sprint Planning Board\"\\n  },\\n  \"attachments\": [\\n    {\\n      \"fileUrl\": \"https://drive.google.com/file/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/view\",\\n      \"title\": \"view\"\\n    },\\n    {\\n      \"fileUrl\": \"https://docs.google.com/spreadsheets/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/edit\",\\n      \"title\": \"edit\"\\n    }\\n  ],\\n  \"eventType\": \"default\",\\n  \"birthdayProperties\": null,\\n  \"focusTimeProperties\": null,\\n  \"outOfOfficeProperties\": null,\\n  \"workingLocationProperties\": null\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'type': 'ai_message',\n",
              "     'content': '',\n",
              "     'tool_calls': [{'name': 'create_event',\n",
              "       'args': {'calendarId': 'alice-projects',\n",
              "        'summary': 'Q4 Initiative Kickoff – Engineering & UX',\n",
              "        'start': {'dateTime': '2026-01-29T10:00:00-05:00',\n",
              "         'timeZone': 'America/New_York'},\n",
              "        'end': {'dateTime': '2026-01-29T12:00:00-05:00',\n",
              "         'timeZone': 'America/New_York'},\n",
              "        'sendUpdates': 'all'}}]},\n",
              "    {'type': 'tool_result',\n",
              "     'tool_name': 'create_event',\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 7,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'create_event',\n",
              "        'arguments': {'calendarId': 'alice-projects',\n",
              "         'summary': 'Q4 Initiative Kickoff – Engineering & UX',\n",
              "         'start': {'dateTime': '2026-01-29T10:00:00-05:00',\n",
              "          'timeZone': 'America/New_York'},\n",
              "         'end': {'dateTime': '2026-01-29T12:00:00-05:00',\n",
              "          'timeZone': 'America/New_York'},\n",
              "         'sendUpdates': 'all'}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#event\",\\n  \"etag\": \"\\\\\"1769516163.408931\\\\\"\",\\n  \"id\": \"d4a790ae-eddb-41f2-ae65-b8c5c5234978\",\\n  \"status\": \"confirmed\",\\n  \"htmlLink\": \"https://calendar.google.com/event?eid=d4a790ae-eddb-41f2-ae65-b8c5c5234978\",\\n  \"created\": \"2026-01-27T17:46:03.408927\",\\n  \"updated\": \"2026-01-27T17:46:03.408931\",\\n  \"summary\": \"Q4 Initiative Kickoff \\\\u2013 Engineering & UX\",\\n  \"description\": null,\\n  \"location\": null,\\n  \"colorId\": null,\\n  \"creator\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.manager@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"organizer\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.manager@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"start\": {\\n    \"dateTime\": \"2026-01-29T10:00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"end\": {\\n    \"dateTime\": \"2026-01-29T12:00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"endTimeUnspecified\": false,\\n  \"recurrence\": [],\\n  \"recurringEventId\": null,\\n  \"originalStartTime\": {\\n    \"dateTime\": \"2026-01-29T10:00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"transparency\": \"opaque\",\\n  \"visibility\": \"default\",\\n  \"iCalUID\": \"d4a790ae-eddb-41f2-ae65-b8c5c5234978@calendar.google.com\",\\n  \"sequence\": 0,\\n  \"attendees\": [],\\n  \"attendeesOmitted\": false,\\n  \"extendedProperties\": null,\\n  \"hangoutLink\": null,\\n  \"conferenceData\": null,\\n  \"guestsCanInviteOthers\": true,\\n  \"guestsCanModify\": false,\\n  \"guestsCanSeeOtherGuests\": true,\\n  \"privateCopy\": false,\\n  \"locked\": false,\\n  \"reminders\": {\\n    \"overrides\": [],\\n    \"useDefault\": false\\n  },\\n  \"source\": null,\\n  \"attachments\": [],\\n  \"eventType\": \"default\",\\n  \"birthdayProperties\": null,\\n  \"focusTimeProperties\": null,\\n  \"outOfOfficeProperties\": null,\\n  \"workingLocationProperties\": null\\n}',\n",
              "        'status_code': 201,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'type': 'ai_message',\n",
              "     'content': '- **Project Management calendar**: confirmed it’s **visible and selected** (Calendar ID: `alice-projects`).\\n- **Moved latest “Sprint Planning & Architecture Review”**: moved event `event-corrected-001` from **Project Management** → **Main (primary) calendar** (`alice-primary`), and updated the description to:  \\n  **“Updated for Q4 planning with new architecture goals and sprint alignment.”**\\n- **Created new event** on **Project Management** calendar:\\n  - **Title:** Q4 Initiative Kickoff – Engineering & UX\\n  - **When:** **Thu, Jan 29, 2026, 10:00 AM – 12:00 PM** (America/New_York)\\n  - **Event ID:** `d4a790ae-eddb-41f2-ae65-b8c5c5234978`',\n",
              "     'tool_calls': []}],\n",
              "   'tools_used': ['get_calendar_list',\n",
              "    'update_calendar_in_list',\n",
              "    'list_events',\n",
              "    'move_event',\n",
              "    'patch_event',\n",
              "    'create_event'],\n",
              "   'tool_results': [{'tool_name': 'get_calendar_list',\n",
              "     'arguments': {},\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 2,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'get_calendar_list',\n",
              "        'arguments': {}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#calendarList\",\\n  \"etag\": \"etag-list-db_1769535944605_7a0xldyiq\",\\n  \"nextPageToken\": null,\\n  \"nextSyncToken\": \"MjAyNi0wMS0yN1QxNzo0NTo0OS4xMzg3NTU=\",\\n  \"items\": [\\n    {\\n      \"kind\": \"calendar#calendarListEntry\",\\n      \"etag\": \"etag-list-alice-primary-2026-01-27T17:45:45\",\\n      \"id\": \"alice-primary\",\\n      \"summary\": \"Alice Johnson\",\\n      \"description\": \"Primary calendar for Alice Johnson - Project Manager\",\\n      \"location\": null,\\n      \"timeZone\": \"America/New_York\",\\n      \"summaryOverride\": null,\\n      \"colorId\": \"1\",\\n      \"backgroundColor\": null,\\n      \"foregroundColor\": null,\\n      \"hidden\": false,\\n      \"selected\": true,\\n      \"accessRole\": \"owner\",\\n      \"defaultReminders\": null,\\n      \"notificationSettings\": null,\\n      \"primary\": true,\\n      \"deleted\": false,\\n      \"conferenceProperties\": {\\n        \"allowedConferenceSolutionTypes\": []\\n      }\\n    },\\n    {\\n      \"kind\": \"calendar#calendarListEntry\",\\n      \"etag\": \"etag-list-alice-projects-2026-01-27T17:45:45\",\\n      \"id\": \"alice-projects\",\\n      \"summary\": \"Project Management\",\\n      \"description\": \"Project meetings, deadlines, and milestones\",\\n      \"location\": null,\\n      \"timeZone\": \"America/New_York\",\\n      \"summaryOverride\": null,\\n      \"colorId\": \"7\",\\n      \"backgroundColor\": null,\\n      \"foregroundColor\": null,\\n      \"hidden\": false,\\n      \"selected\": true,\\n      \"accessRole\": \"owner\",\\n      \"defaultReminders\": null,\\n      \"notificationSettings\": null,\\n      \"primary\": false,\\n      \"deleted\": false,\\n      \"conferenceProperties\": {\\n        \"allowedConferenceSolutionTypes\": []\\n      }\\n    },\\n    {\\n      \"kind\": \"calendar#calendarListEntry\",\\n      \"etag\": \"etag-list-alice-team-2026-01-27T17:45:45\",\\n      \"id\": \"alice-team\",\\n      \"summary\": \"Team Coordination\",\\n      \"description\": \"Team meetings, 1-on-1s, and team events\",\\n      \"location\": null,\\n      \"timeZone\": \"America/New_York\",\\n      \"summaryOverride\": null,\\n      \"colorId\": \"11\",\\n      \"backgroundColor\": null,\\n      \"foregroundColor\": null,\\n      \"hidden\": false,\\n      \"selected\": true,\\n      \"accessRole\": \"owner\",\\n      \"defaultReminders\": null,\\n      \"notificationSettings\": null,\\n      \"primary\": false,\\n      \"deleted\": false,\\n      \"conferenceProperties\": {\\n        \"allowedConferenceSolutionTypes\": []\\n      }\\n    }\\n  ]\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'tool_name': 'update_calendar_in_list',\n",
              "     'arguments': {'calendarId': 'alice-projects',\n",
              "      'hidden': False,\n",
              "      'selected': True},\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 3,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'update_calendar_in_list',\n",
              "        'arguments': {'calendarId': 'alice-projects',\n",
              "         'hidden': False,\n",
              "         'selected': True}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#calendarListEntry\",\\n  \"etag\": \"etag-list-alice-projects-2026-01-27T17:45:45\",\\n  \"id\": \"alice-projects\",\\n  \"summary\": \"Project Management\",\\n  \"description\": \"Project meetings, deadlines, and milestones\",\\n  \"location\": null,\\n  \"timeZone\": \"America/New_York\",\\n  \"summaryOverride\": null,\\n  \"colorId\": \"7\",\\n  \"backgroundColor\": null,\\n  \"foregroundColor\": null,\\n  \"hidden\": false,\\n  \"selected\": true,\\n  \"accessRole\": \"owner\",\\n  \"defaultReminders\": null,\\n  \"notificationSettings\": null,\\n  \"primary\": false,\\n  \"deleted\": false,\\n  \"conferenceProperties\": {\\n    \"allowedConferenceSolutionTypes\": []\\n  }\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'tool_name': 'list_events',\n",
              "     'arguments': {'calendarId': 'alice-projects',\n",
              "      'q': 'Sprint Planning & Architecture Review',\n",
              "      'singleEvents': True,\n",
              "      'orderBy': 'startTime',\n",
              "      'timeMin': '2025-01-27T00:00:00-05:00',\n",
              "      'timeMax': '2026-12-31T23:59:59-05:00',\n",
              "      'maxResults': 2500},\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 4,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'list_events',\n",
              "        'arguments': {'calendarId': 'alice-projects',\n",
              "         'q': 'Sprint Planning & Architecture Review',\n",
              "         'singleEvents': True,\n",
              "         'orderBy': 'startTime',\n",
              "         'timeMin': '2025-01-27T00:00:00-05:00',\n",
              "         'timeMax': '2026-12-31T23:59:59-05:00',\n",
              "         'maxResults': 2500}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#events\",\\n  \"etag\": \"etag-events-alice-projects\",\\n  \"summary\": \"Project Management\",\\n  \"description\": \"Project meetings, deadlines, and milestones\",\\n  \"updated\": \"2026-01-27T17:45:54.715123+00:00\",\\n  \"timeZone\": \"America/New_York\",\\n  \"accessRole\": \"owner\",\\n  \"defaultReminders\": [],\\n  \"nextPageToken\": null,\\n  \"nextSyncToken\": null,\\n  \"items\": [\\n    {\\n      \"kind\": \"calendar#event\",\\n      \"etag\": \"\\\\\"1769516145.0\\\\\"\",\\n      \"id\": \"event-corrected-001\",\\n      \"status\": \"confirmed\",\\n      \"htmlLink\": \"https://calendar.google.com/event?eid=event-corrected-001\",\\n      \"created\": \"2026-01-27T17:45:45\",\\n      \"updated\": \"2026-01-27T17:45:45\",\\n      \"summary\": \"Sprint Planning & Architecture Review\",\\n      \"description\": \"Detailed sprint planning session with architecture discussion for Q4 features. We\\'ll review user stories, estimate effort, and plan the technical approach.\",\\n      \"location\": \"Conference Room A, Building 1\",\\n      \"colorId\": \"7\",\\n      \"creator\": {\\n        \"id\": \"alice_manager\",\\n        \"email\": \"alice.johnson@techcorp.com\",\\n        \"displayName\": \"Alice Johnson\",\\n        \"self\": true\\n      },\\n      \"organizer\": {\\n        \"id\": \"alice_manager\",\\n        \"email\": \"alice.johnson@techcorp.com\",\\n        \"displayName\": \"Alice Johnson\",\\n        \"self\": true\\n      },\\n      \"start\": {\\n        \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n        \"date\": null,\\n        \"timeZone\": \"America/New_York\"\\n      },\\n      \"end\": {\\n        \"dateTime\": \"2026-01-27T11:00:00+00:00\",\\n        \"date\": null,\\n        \"timeZone\": \"America/New_York\"\\n      },\\n      \"endTimeUnspecified\": false,\\n      \"recurrence\": [],\\n      \"recurringEventId\": \"NULL\",\\n      \"originalStartTime\": {\\n        \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n        \"date\": null,\\n        \"timeZone\": \"America/New_York\"\\n      },\\n      \"transparency\": null,\\n      \"visibility\": \"default\",\\n      \"iCalUID\": \"event-corrected-001@gmail.com\",\\n      \"sequence\": 1,\\n      \"attendees\": [\\n        {\\n          \"id\": \"att-corrected-001\",\\n          \"email\": \"alice.manager@techcorp.com\",\\n          \"displayName\": \"Alice Johnson\",\\n          \"self\": false,\\n          \"organizer\": false,\\n          \"responseStatus\": \"accepted\",\\n          \"comment\": \"Looking forward to planning Q4!\",\\n          \"additionalGuests\": 0,\\n          \"optional\": false,\\n          \"resource\": false\\n        },\\n        {\\n          \"id\": \"att-corrected-002\",\\n          \"email\": \"bob.smith@techcorp.com\",\\n          \"displayName\": \"Bob Smith\",\\n          \"self\": false,\\n          \"organizer\": false,\\n          \"responseStatus\": \"accepted\",\\n          \"comment\": null,\\n          \"additionalGuests\": 0,\\n          \"optional\": false,\\n          \"resource\": false\\n        },\\n        {\\n          \"id\": \"att-corrected-003\",\\n          \"email\": \"carol.white@techcorp.com\",\\n          \"displayName\": \"Carol White\",\\n          \"self\": false,\\n          \"organizer\": false,\\n          \"responseStatus\": \"tentative\",\\n          \"comment\": \"Will join if no conflicts with user research session\",\\n          \"additionalGuests\": 0,\\n          \"optional\": true,\\n          \"resource\": false\\n        },\\n        {\\n          \"id\": \"att-corrected-004\",\\n          \"email\": null,\\n          \"displayName\": \"Conference Room A\",\\n          \"self\": false,\\n          \"organizer\": false,\\n          \"responseStatus\": \"accepted\",\\n          \"comment\": null,\\n          \"additionalGuests\": 0,\\n          \"optional\": false,\\n          \"resource\": true\\n        }\\n      ],\\n      \"attendeesOmitted\": false,\\n      \"extendedProperties\": {\\n        \"private\": {\\n          \"departmentBudget\": \"engineering\",\\n          \"projectCode\": \"PROJ-2024-Q4\"\\n        },\\n        \"shared\": {\\n          \"meetingType\": \"sprint_planning\",\\n          \"priority\": \"high\"\\n        }\\n      },\\n      \"hangoutLink\": null,\\n      \"conferenceData\": {\\n        \"conferenceSolution\": {\\n          \"iconUri\": null,\\n          \"key\": {\\n            \"type\": \"hangoutsMeet\"\\n          },\\n          \"name\": null\\n        },\\n        \"createRequest\": {\\n          \"conferenceSolutionKey\": null,\\n          \"requestId\": \"req-sprint-planning-001\",\\n          \"status\": {\\n            \"statusCode\": \"success\"\\n          }\\n        },\\n        \"entryPoints\": [\\n          {\\n            \"accessCode\": null,\\n            \"entryPointType\": \"video\",\\n            \"label\": null,\\n            \"meetingCode\": null,\\n            \"passcode\": null,\\n            \"password\": null,\\n            \"pin\": null,\\n            \"uri\": \"https://meet.google.com/abc-defg-hij\"\\n          }\\n        ],\\n        \"notes\": null,\\n        \"signature\": null\\n      },\\n      \"guestsCanInviteOthers\": true,\\n      \"guestsCanModify\": false,\\n      \"guestsCanSeeOtherGuests\": true,\\n      \"privateCopy\": null,\\n      \"locked\": null,\\n      \"reminders\": {\\n        \"overrides\": [\\n          {\\n            \"method\": \"email\",\\n            \"minutes\": 1440\\n          },\\n          {\\n            \"method\": \"popup\",\\n            \"minutes\": 30\\n          }\\n        ],\\n        \"useDefault\": false\\n      },\\n      \"source\": {\\n        \"url\": \"https://jira.techcorp.com/sprint-planning-q4\",\\n        \"title\": \"Sprint Planning Board\"\\n      },\\n      \"attachments\": [\\n        {\\n          \"fileUrl\": \"https://drive.google.com/file/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/view\",\\n          \"title\": \"view\"\\n        },\\n        {\\n          \"fileUrl\": \"https://docs.google.com/spreadsheets/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/edit\",\\n          \"title\": \"edit\"\\n        }\\n      ],\\n      \"eventType\": \"default\",\\n      \"birthdayProperties\": null,\\n      \"focusTimeProperties\": null,\\n      \"outOfOfficeProperties\": null,\\n      \"workingLocationProperties\": null\\n    }\\n  ]\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'tool_name': 'move_event',\n",
              "     'arguments': {'calendarId': 'alice-projects',\n",
              "      'eventId': 'event-corrected-001',\n",
              "      'destination': 'alice-primary',\n",
              "      'sendUpdates': 'all'},\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 5,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'move_event',\n",
              "        'arguments': {'calendarId': 'alice-projects',\n",
              "         'eventId': 'event-corrected-001',\n",
              "         'destination': 'alice-primary',\n",
              "         'sendUpdates': 'all'}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#event\",\\n  \"etag\": \"\\\\\"1769516157.58162\\\\\"\",\\n  \"id\": \"event-corrected-001\",\\n  \"status\": \"confirmed\",\\n  \"htmlLink\": \"https://calendar.google.com/event?eid=event-corrected-001\",\\n  \"created\": \"2026-01-27T17:45:45\",\\n  \"updated\": \"2026-01-27T17:45:57.581620\",\\n  \"summary\": \"Sprint Planning & Architecture Review\",\\n  \"description\": \"Detailed sprint planning session with architecture discussion for Q4 features. We\\'ll review user stories, estimate effort, and plan the technical approach.\",\\n  \"location\": \"Conference Room A, Building 1\",\\n  \"colorId\": \"7\",\\n  \"creator\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.johnson@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"organizer\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.johnson@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"start\": {\\n    \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"end\": {\\n    \"dateTime\": \"2026-01-27T11:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"endTimeUnspecified\": false,\\n  \"recurrence\": [],\\n  \"recurringEventId\": \"NULL\",\\n  \"originalStartTime\": {\\n    \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"transparency\": null,\\n  \"visibility\": \"default\",\\n  \"iCalUID\": \"event-corrected-001@gmail.com\",\\n  \"sequence\": 1,\\n  \"attendees\": [\\n    {\\n      \"id\": \"att-corrected-001\",\\n      \"email\": \"alice.manager@techcorp.com\",\\n      \"displayName\": \"Alice Johnson\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": \"Looking forward to planning Q4!\",\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-002\",\\n      \"email\": \"bob.smith@techcorp.com\",\\n      \"displayName\": \"Bob Smith\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": null,\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-003\",\\n      \"email\": \"carol.white@techcorp.com\",\\n      \"displayName\": \"Carol White\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"tentative\",\\n      \"comment\": \"Will join if no conflicts with user research session\",\\n      \"additionalGuests\": 0,\\n      \"optional\": true,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-004\",\\n      \"email\": null,\\n      \"displayName\": \"Conference Room A\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": null,\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": true\\n    }\\n  ],\\n  \"attendeesOmitted\": false,\\n  \"extendedProperties\": {\\n    \"private\": {\\n      \"departmentBudget\": \"engineering\",\\n      \"projectCode\": \"PROJ-2024-Q4\"\\n    },\\n    \"shared\": {\\n      \"meetingType\": \"sprint_planning\",\\n      \"priority\": \"high\"\\n    }\\n  },\\n  \"hangoutLink\": null,\\n  \"conferenceData\": {\\n    \"conferenceSolution\": {\\n      \"iconUri\": null,\\n      \"key\": {\\n        \"type\": \"hangoutsMeet\"\\n      },\\n      \"name\": null\\n    },\\n    \"createRequest\": {\\n      \"conferenceSolutionKey\": null,\\n      \"requestId\": \"req-sprint-planning-001\",\\n      \"status\": {\\n        \"statusCode\": \"success\"\\n      }\\n    },\\n    \"entryPoints\": [\\n      {\\n        \"accessCode\": null,\\n        \"entryPointType\": \"video\",\\n        \"label\": null,\\n        \"meetingCode\": null,\\n        \"passcode\": null,\\n        \"password\": null,\\n        \"pin\": null,\\n        \"uri\": \"https://meet.google.com/abc-defg-hij\"\\n      }\\n    ],\\n    \"notes\": null,\\n    \"signature\": null\\n  },\\n  \"guestsCanInviteOthers\": true,\\n  \"guestsCanModify\": false,\\n  \"guestsCanSeeOtherGuests\": true,\\n  \"privateCopy\": null,\\n  \"locked\": null,\\n  \"reminders\": {\\n    \"overrides\": [\\n      {\\n        \"method\": \"email\",\\n        \"minutes\": 1440\\n      },\\n      {\\n        \"method\": \"popup\",\\n        \"minutes\": 30\\n      }\\n    ],\\n    \"useDefault\": false\\n  },\\n  \"source\": {\\n    \"url\": \"https://jira.techcorp.com/sprint-planning-q4\",\\n    \"title\": \"Sprint Planning Board\"\\n  },\\n  \"attachments\": [\\n    {\\n      \"fileUrl\": \"https://drive.google.com/file/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/view\",\\n      \"title\": \"view\"\\n    },\\n    {\\n      \"fileUrl\": \"https://docs.google.com/spreadsheets/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/edit\",\\n      \"title\": \"edit\"\\n    }\\n  ],\\n  \"eventType\": \"default\",\\n  \"birthdayProperties\": null,\\n  \"focusTimeProperties\": null,\\n  \"outOfOfficeProperties\": null,\\n  \"workingLocationProperties\": null\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'tool_name': 'patch_event',\n",
              "     'arguments': {'calendarId': 'alice-primary',\n",
              "      'eventId': 'event-corrected-001',\n",
              "      'description': 'Updated for Q4 planning with new architecture goals and sprint alignment.',\n",
              "      'sendUpdates': 'all'},\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 6,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'patch_event',\n",
              "        'arguments': {'calendarId': 'alice-primary',\n",
              "         'eventId': 'event-corrected-001',\n",
              "         'description': 'Updated for Q4 planning with new architecture goals and sprint alignment.',\n",
              "         'sendUpdates': 'all'}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#event\",\\n  \"etag\": \"\\\\\"1769516160.36052\\\\\"\",\\n  \"id\": \"event-corrected-001\",\\n  \"status\": \"confirmed\",\\n  \"htmlLink\": \"https://calendar.google.com/event?eid=event-corrected-001\",\\n  \"created\": \"2026-01-27T17:45:45\",\\n  \"updated\": \"2026-01-27T17:46:00.360520\",\\n  \"summary\": \"Sprint Planning & Architecture Review\",\\n  \"description\": \"Updated for Q4 planning with new architecture goals and sprint alignment.\",\\n  \"location\": \"Conference Room A, Building 1\",\\n  \"colorId\": \"7\",\\n  \"creator\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.johnson@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"organizer\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.johnson@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"start\": {\\n    \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"end\": {\\n    \"dateTime\": \"2026-01-27T11:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"endTimeUnspecified\": false,\\n  \"recurrence\": [],\\n  \"recurringEventId\": \"NULL\",\\n  \"originalStartTime\": {\\n    \"dateTime\": \"2026-01-27T09:00:00+00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"transparency\": null,\\n  \"visibility\": \"default\",\\n  \"iCalUID\": \"event-corrected-001@gmail.com\",\\n  \"sequence\": 2,\\n  \"attendees\": [\\n    {\\n      \"id\": \"att-corrected-001\",\\n      \"email\": \"alice.manager@techcorp.com\",\\n      \"displayName\": \"Alice Johnson\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": \"Looking forward to planning Q4!\",\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-002\",\\n      \"email\": \"bob.smith@techcorp.com\",\\n      \"displayName\": \"Bob Smith\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": null,\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-003\",\\n      \"email\": \"carol.white@techcorp.com\",\\n      \"displayName\": \"Carol White\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"tentative\",\\n      \"comment\": \"Will join if no conflicts with user research session\",\\n      \"additionalGuests\": 0,\\n      \"optional\": true,\\n      \"resource\": false\\n    },\\n    {\\n      \"id\": \"att-corrected-004\",\\n      \"email\": null,\\n      \"displayName\": \"Conference Room A\",\\n      \"self\": false,\\n      \"organizer\": false,\\n      \"responseStatus\": \"accepted\",\\n      \"comment\": null,\\n      \"additionalGuests\": 0,\\n      \"optional\": false,\\n      \"resource\": true\\n    }\\n  ],\\n  \"attendeesOmitted\": false,\\n  \"extendedProperties\": {\\n    \"private\": {\\n      \"departmentBudget\": \"engineering\",\\n      \"projectCode\": \"PROJ-2024-Q4\"\\n    },\\n    \"shared\": {\\n      \"meetingType\": \"sprint_planning\",\\n      \"priority\": \"high\"\\n    }\\n  },\\n  \"hangoutLink\": null,\\n  \"conferenceData\": {\\n    \"conferenceSolution\": {\\n      \"iconUri\": null,\\n      \"key\": {\\n        \"type\": \"hangoutsMeet\"\\n      },\\n      \"name\": null\\n    },\\n    \"createRequest\": {\\n      \"conferenceSolutionKey\": null,\\n      \"requestId\": \"req-sprint-planning-001\",\\n      \"status\": {\\n        \"statusCode\": \"success\"\\n      }\\n    },\\n    \"entryPoints\": [\\n      {\\n        \"accessCode\": null,\\n        \"entryPointType\": \"video\",\\n        \"label\": null,\\n        \"meetingCode\": null,\\n        \"passcode\": null,\\n        \"password\": null,\\n        \"pin\": null,\\n        \"uri\": \"https://meet.google.com/abc-defg-hij\"\\n      }\\n    ],\\n    \"notes\": null,\\n    \"signature\": null\\n  },\\n  \"guestsCanInviteOthers\": true,\\n  \"guestsCanModify\": false,\\n  \"guestsCanSeeOtherGuests\": true,\\n  \"privateCopy\": null,\\n  \"locked\": null,\\n  \"reminders\": {\\n    \"overrides\": [\\n      {\\n        \"method\": \"email\",\\n        \"minutes\": 1440\\n      },\\n      {\\n        \"method\": \"popup\",\\n        \"minutes\": 30\\n      }\\n    ],\\n    \"useDefault\": false\\n  },\\n  \"source\": {\\n    \"url\": \"https://jira.techcorp.com/sprint-planning-q4\",\\n    \"title\": \"Sprint Planning Board\"\\n  },\\n  \"attachments\": [\\n    {\\n      \"fileUrl\": \"https://drive.google.com/file/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/view\",\\n      \"title\": \"view\"\\n    },\\n    {\\n      \"fileUrl\": \"https://docs.google.com/spreadsheets/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/edit\",\\n      \"title\": \"edit\"\\n    }\\n  ],\\n  \"eventType\": \"default\",\\n  \"birthdayProperties\": null,\\n  \"focusTimeProperties\": null,\\n  \"outOfOfficeProperties\": null,\\n  \"workingLocationProperties\": null\\n}',\n",
              "        'status_code': 200,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}},\n",
              "    {'tool_name': 'create_event',\n",
              "     'arguments': {'calendarId': 'alice-projects',\n",
              "      'summary': 'Q4 Initiative Kickoff – Engineering & UX',\n",
              "      'start': {'dateTime': '2026-01-29T10:00:00-05:00',\n",
              "       'timeZone': 'America/New_York'},\n",
              "      'end': {'dateTime': '2026-01-29T12:00:00-05:00',\n",
              "       'timeZone': 'America/New_York'},\n",
              "      'sendUpdates': 'all'},\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': 1.0,\n",
              "       'metadata': {'step': 7,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'create_event',\n",
              "        'arguments': {'calendarId': 'alice-projects',\n",
              "         'summary': 'Q4 Initiative Kickoff – Engineering & UX',\n",
              "         'start': {'dateTime': '2026-01-29T10:00:00-05:00',\n",
              "          'timeZone': 'America/New_York'},\n",
              "         'end': {'dateTime': '2026-01-29T12:00:00-05:00',\n",
              "          'timeZone': 'America/New_York'},\n",
              "         'sendUpdates': 'all'}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': '{\\n  \"kind\": \"calendar#event\",\\n  \"etag\": \"\\\\\"1769516163.408931\\\\\"\",\\n  \"id\": \"d4a790ae-eddb-41f2-ae65-b8c5c5234978\",\\n  \"status\": \"confirmed\",\\n  \"htmlLink\": \"https://calendar.google.com/event?eid=d4a790ae-eddb-41f2-ae65-b8c5c5234978\",\\n  \"created\": \"2026-01-27T17:46:03.408927\",\\n  \"updated\": \"2026-01-27T17:46:03.408931\",\\n  \"summary\": \"Q4 Initiative Kickoff \\\\u2013 Engineering & UX\",\\n  \"description\": null,\\n  \"location\": null,\\n  \"colorId\": null,\\n  \"creator\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.manager@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"organizer\": {\\n    \"id\": \"alice_manager\",\\n    \"email\": \"alice.manager@techcorp.com\",\\n    \"displayName\": \"Alice Johnson\",\\n    \"self\": true\\n  },\\n  \"start\": {\\n    \"dateTime\": \"2026-01-29T10:00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"end\": {\\n    \"dateTime\": \"2026-01-29T12:00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"endTimeUnspecified\": false,\\n  \"recurrence\": [],\\n  \"recurringEventId\": null,\\n  \"originalStartTime\": {\\n    \"dateTime\": \"2026-01-29T10:00:00\",\\n    \"date\": null,\\n    \"timeZone\": \"America/New_York\"\\n  },\\n  \"transparency\": \"opaque\",\\n  \"visibility\": \"default\",\\n  \"iCalUID\": \"d4a790ae-eddb-41f2-ae65-b8c5c5234978@calendar.google.com\",\\n  \"sequence\": 0,\\n  \"attendees\": [],\\n  \"attendeesOmitted\": false,\\n  \"extendedProperties\": null,\\n  \"hangoutLink\": null,\\n  \"conferenceData\": null,\\n  \"guestsCanInviteOthers\": true,\\n  \"guestsCanModify\": false,\\n  \"guestsCanSeeOtherGuests\": true,\\n  \"privateCopy\": false,\\n  \"locked\": false,\\n  \"reminders\": {\\n    \"overrides\": [],\\n    \"useDefault\": false\\n  },\\n  \"source\": null,\\n  \"attachments\": [],\\n  \"eventType\": \"default\",\\n  \"birthdayProperties\": null,\\n  \"focusTimeProperties\": null,\\n  \"outOfOfficeProperties\": null,\\n  \"workingLocationProperties\": null\\n}',\n",
              "        'status_code': 201,\n",
              "        'isError': False}},\n",
              "      'reward': 1.0}}],\n",
              "   'verification_results': {'Project Calendar Visible': {'passed': True,\n",
              "     'expected': 1,\n",
              "     'actual': 1,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM calendars WHERE calendar_id='alice-projects' AND hidden=0 AND selected=1;\",\n",
              "     'details': 'Comparison equals: 1 vs 1'},\n",
              "    'Event Moved to Primary': {'passed': True,\n",
              "     'expected': 1,\n",
              "     'actual': 1,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM events WHERE event_id='event-corrected-001' AND calendar_id='alice-primary';\",\n",
              "     'details': 'Comparison equals: 1 vs 1'},\n",
              "    'Event Description Updated': {'passed': True,\n",
              "     'expected': 1,\n",
              "     'actual': 1,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM events WHERE event_id='event-corrected-001' AND description LIKE '%Q4%' AND description LIKE '%planning%' AND description LIKE '%architecture%' \",\n",
              "     'details': 'Comparison equals: 1 vs 1'},\n",
              "    'Kickoff Event Created': {'passed': False,\n",
              "     'expected': 1,\n",
              "     'actual': 0,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM events WHERE summary='Q4 Initiative Kickoff – Engineering & UX' AND calendar_id='alice-projects' AND start_datetime LIKE '%2026-01-15 10:00%'\\nAND end_datetime LIKE '%2026-01-15 12:00:%'AND status='confirmed'\",\n",
              "     'details': 'Comparison equals: 0 vs 1'},\n",
              "    'Verify Old mapping removed': {'passed': True,\n",
              "     'expected': 0,\n",
              "     'actual': 0,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM events WHERE event_id='event-corrected-001' AND calendar_id='alice-projects';\",\n",
              "     'details': 'Comparison equals: 0 vs 0'}},\n",
              "   'verification_summary': {'total': 5,\n",
              "    'passed': 4,\n",
              "    'failed': 1,\n",
              "    'pass_rate': 0.8},\n",
              "   'overall_success': False},\n",
              "  {'run_number': 2,\n",
              "   'started_at': '2026-01-27T17:46:10.067973+00:00',\n",
              "   'execution_time_ms': 16884,\n",
              "   'model_response': 'I can do this, but I’m currently blocked by an API issue when listing your calendars: the `get_calendar_list` endpoint is returning entries with `accessRole: \"none\"`, which our connector rejects (it only accepts `freeBusyReader/reader/writer/owner`). Because of that, I can’t reliably identify:\\n\\n- which calendar is your **“Project Management”** calendar (and whether it’s hidden/unselected), or  \\n- your **primary (“main”)** calendar ID, or  \\n- where the latest **“Sprint Planning & Architecture Review”** event currently lives so I can move it.\\n\\n### What I *can* do immediately once calendar listing is working\\n1. Ensure **Project Management** is **visible + selected** in your calendar list.\\n2. Search for **“Sprint Planning & Architecture Review”**, pick the latest occurrence, and **move it to your primary calendar**, then update its description to:  \\n   > Updated for Q4 planning with new architecture goals and sprint alignment.\\n3. Create **“Q4 Initiative Kickoff – Engineering & UX”** on the **Project Management** calendar for **next Thursday 10:00–12:00** (using your calendar time zone).\\n\\n### One quick question so I can proceed even without calendar listing\\nWhich of these do you prefer?\\n\\nA) Tell me the **calendar ID** (or the exact calendar email) for **Project Management** (and confirm your primary is just `\"primary\"`), **and** tell me which calendar currently contains “Sprint Planning & Architecture Review” (or share the event link).  \\n**or**  \\nB) If you don’t have IDs, tell me the **exact title** of your primary calendar as it appears in your list, and any distinguishing detail for “Project Management” (exact name or color). I’ll retry with a different lookup strategy as soon as the calendar-list issue is resolved.\\n\\nReply with A or B and the details, and I’ll execute the whole flow end-to-end.',\n",
              "   'conversation_flow': [{'type': 'ai_message',\n",
              "     'content': '',\n",
              "     'tool_calls': [{'name': 'get_calendar_list', 'args': {}}]},\n",
              "    {'type': 'tool_result',\n",
              "     'tool_name': 'get_calendar_list',\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': -0.5,\n",
              "       'metadata': {'step': 1,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'get_calendar_list',\n",
              "        'arguments': {}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': \"3 validation errors for CalendarListResponse\\nitems.0.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\\nitems.1.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\\nitems.2.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\",\n",
              "        'status_code': 400,\n",
              "        'isError': True}},\n",
              "      'reward': -0.5}},\n",
              "    {'type': 'ai_message',\n",
              "     'content': '',\n",
              "     'tool_calls': [{'name': 'get_calendar_list',\n",
              "       'args': {'showHidden': True, 'showDeleted': True}}]},\n",
              "    {'type': 'tool_result',\n",
              "     'tool_name': 'get_calendar_list',\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': -0.5,\n",
              "       'metadata': {'step': 2,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'get_calendar_list',\n",
              "        'arguments': {'showHidden': True, 'showDeleted': True}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': \"3 validation errors for CalendarListResponse\\nitems.0.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\\nitems.1.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\\nitems.2.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\",\n",
              "        'status_code': 400,\n",
              "        'isError': True}},\n",
              "      'reward': -0.5}},\n",
              "    {'type': 'ai_message',\n",
              "     'content': 'I can do this, but I’m currently blocked by an API issue when listing your calendars: the `get_calendar_list` endpoint is returning entries with `accessRole: \"none\"`, which our connector rejects (it only accepts `freeBusyReader/reader/writer/owner`). Because of that, I can’t reliably identify:\\n\\n- which calendar is your **“Project Management”** calendar (and whether it’s hidden/unselected), or  \\n- your **primary (“main”)** calendar ID, or  \\n- where the latest **“Sprint Planning & Architecture Review”** event currently lives so I can move it.\\n\\n### What I *can* do immediately once calendar listing is working\\n1. Ensure **Project Management** is **visible + selected** in your calendar list.\\n2. Search for **“Sprint Planning & Architecture Review”**, pick the latest occurrence, and **move it to your primary calendar**, then update its description to:  \\n   > Updated for Q4 planning with new architecture goals and sprint alignment.\\n3. Create **“Q4 Initiative Kickoff – Engineering & UX”** on the **Project Management** calendar for **next Thursday 10:00–12:00** (using your calendar time zone).\\n\\n### One quick question so I can proceed even without calendar listing\\nWhich of these do you prefer?\\n\\nA) Tell me the **calendar ID** (or the exact calendar email) for **Project Management** (and confirm your primary is just `\"primary\"`), **and** tell me which calendar currently contains “Sprint Planning & Architecture Review” (or share the event link).  \\n**or**  \\nB) If you don’t have IDs, tell me the **exact title** of your primary calendar as it appears in your list, and any distinguishing detail for “Project Management” (exact name or color). I’ll retry with a different lookup strategy as soon as the calendar-list issue is resolved.\\n\\nReply with A or B and the details, and I’ll execute the whole flow end-to-end.',\n",
              "     'tool_calls': []}],\n",
              "   'tools_used': ['get_calendar_list'],\n",
              "   'tool_results': [{'tool_name': 'get_calendar_list',\n",
              "     'arguments': {},\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': -0.5,\n",
              "       'metadata': {'step': 1,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'get_calendar_list',\n",
              "        'arguments': {}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': \"3 validation errors for CalendarListResponse\\nitems.0.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\\nitems.1.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\\nitems.2.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\",\n",
              "        'status_code': 400,\n",
              "        'isError': True}},\n",
              "      'reward': -0.5}},\n",
              "    {'tool_name': 'get_calendar_list',\n",
              "     'arguments': {'showHidden': True, 'showDeleted': True},\n",
              "     'result': {'success': True,\n",
              "      'result': {'done': False,\n",
              "       'reward': -0.5,\n",
              "       'metadata': {'step': 2,\n",
              "        'action_type': 'tool_call',\n",
              "        'tool_name': 'get_calendar_list',\n",
              "        'arguments': {'showHidden': True, 'showDeleted': True}},\n",
              "       'success': True,\n",
              "       'error_message': None,\n",
              "       'tools_list': None,\n",
              "       'tool_result': {'text': \"3 validation errors for CalendarListResponse\\nitems.0.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\\nitems.1.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\\nitems.2.accessRole\\n  Input should be 'freeBusyReader', 'reader', 'writer' or 'owner' [type=enum, input_value='none', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.12/v/enum\",\n",
              "        'status_code': 400,\n",
              "        'isError': True}},\n",
              "      'reward': -0.5}}],\n",
              "   'verification_results': {'Project Calendar Visible': {'passed': True,\n",
              "     'expected': 1,\n",
              "     'actual': 1,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM calendars WHERE calendar_id='alice-projects' AND hidden=0 AND selected=1;\",\n",
              "     'details': 'Comparison equals: 1 vs 1'},\n",
              "    'Event Moved to Primary': {'passed': False,\n",
              "     'expected': 1,\n",
              "     'actual': 0,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM events WHERE event_id='event-corrected-001' AND calendar_id='alice-primary';\",\n",
              "     'details': 'Comparison equals: 0 vs 1'},\n",
              "    'Event Description Updated': {'passed': False,\n",
              "     'expected': 1,\n",
              "     'actual': 0,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM events WHERE event_id='event-corrected-001' AND description LIKE '%Q4%' AND description LIKE '%planning%' AND description LIKE '%architecture%' \",\n",
              "     'details': 'Comparison equals: 0 vs 1'},\n",
              "    'Kickoff Event Created': {'passed': False,\n",
              "     'expected': 1,\n",
              "     'actual': 0,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM events WHERE summary='Q4 Initiative Kickoff – Engineering & UX' AND calendar_id='alice-projects' AND start_datetime LIKE '%2026-01-15 10:00%'\\nAND end_datetime LIKE '%2026-01-15 12:00:%'AND status='confirmed'\",\n",
              "     'details': 'Comparison equals: 0 vs 1'},\n",
              "    'Verify Old mapping removed': {'passed': True,\n",
              "     'expected': 0,\n",
              "     'actual': 0,\n",
              "     'comparison_type': 'equals',\n",
              "     'query': \"SELECT COUNT(*) FROM events WHERE event_id='event-corrected-001' AND calendar_id='alice-projects';\",\n",
              "     'details': 'Comparison equals: 0 vs 0'}},\n",
              "   'verification_summary': {'total': 5,\n",
              "    'passed': 2,\n",
              "    'failed': 3,\n",
              "    'pass_rate': 0.4},\n",
              "   'overall_success': False}],\n",
              " 'statistics': {'total_runs': 2,\n",
              "  'successful_runs': 0,\n",
              "  'overall_success_rate': 0.0,\n",
              "  'pass_at_1': 0.0,\n",
              "  'verifier_level_pass_rate': 0.6,\n",
              "  'total_verifiers_checked': 10,\n",
              "  'total_verifiers_passed': 6,\n",
              "  'individual_verifier_stats': {'Project Calendar Visible': {'passed': 2,\n",
              "    'total': 2,\n",
              "    'pass_rate': 1.0},\n",
              "   'Event Moved to Primary': {'passed': 1, 'total': 2, 'pass_rate': 0.5},\n",
              "   'Event Description Updated': {'passed': 1, 'total': 2, 'pass_rate': 0.5},\n",
              "   'Kickoff Event Created': {'passed': 0, 'total': 2, 'pass_rate': 0.0},\n",
              "   'Verify Old mapping removed': {'passed': 2, 'total': 2, 'pass_rate': 1.0}},\n",
              "  'mean_execution_time_ms': 20168.0,\n",
              "  'tool_usage': {'get_calendar_list': 2,\n",
              "   'update_calendar_in_list': 1,\n",
              "   'list_events': 1,\n",
              "   'move_event': 1,\n",
              "   'patch_event': 1,\n",
              "   'create_event': 1}}}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Execute benchmark using CONFIG from cell 5\n",
        "# Simply run: await run_benchmark()\n",
        "\n",
        "async def run_benchmark():\n",
        "    \"\"\"Execute benchmark using CONFIG dictionary from cell 5\"\"\"\n",
        "    try:\n",
        "        # Call main function with CONFIG\n",
        "        result = await main(CONFIG)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Benchmark failed: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "await run_benchmark()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f1LsMbU8E_e"
      },
      "source": [
        "## Results Analysis\n",
        "\n",
        "After running the benchmark, you can analyze the results using the cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "flPzhqIQ8E_f",
        "outputId": "d7026dc7-be33-4a3b-d49a-5d66822a0dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File Name:  benchmark_results_20260127_174626.json\n",
            "{'total_runs': 2, 'successful_runs': 0, 'overall_success_rate': 0.0, 'pass_at_1': 0.0, 'verifier_level_pass_rate': 0.6, 'total_verifiers_checked': 10, 'total_verifiers_passed': 6, 'individual_verifier_stats': {'Project Calendar Visible': {'passed': 2, 'total': 2, 'pass_rate': 1.0}, 'Event Moved to Primary': {'passed': 1, 'total': 2, 'pass_rate': 0.5}, 'Event Description Updated': {'passed': 1, 'total': 2, 'pass_rate': 0.5}, 'Kickoff Event Created': {'passed': 0, 'total': 2, 'pass_rate': 0.0}, 'Verify Old mapping removed': {'passed': 2, 'total': 2, 'pass_rate': 1.0}}, 'mean_execution_time_ms': 20168.0, 'tool_usage': {'get_calendar_list': 2, 'update_calendar_in_list': 1, 'list_events': 1, 'move_event': 1, 'patch_event': 1, 'create_event': 1}}\n",
            "{\n",
            "  \"individual_verifier_stats\": {\n",
            "    \"Event Description Updated\": {\n",
            "      \"pass_rate\": 0.5,\n",
            "      \"passed\": 1,\n",
            "      \"total\": 2\n",
            "    },\n",
            "    \"Event Moved to Primary\": {\n",
            "      \"pass_rate\": 0.5,\n",
            "      \"passed\": 1,\n",
            "      \"total\": 2\n",
            "    },\n",
            "    \"Kickoff Event Created\": {\n",
            "      \"pass_rate\": 0.0,\n",
            "      \"passed\": 0,\n",
            "      \"total\": 2\n",
            "    },\n",
            "    \"Project Calendar Visible\": {\n",
            "      \"pass_rate\": 1.0,\n",
            "      \"passed\": 2,\n",
            "      \"total\": 2\n",
            "    },\n",
            "    \"Verify Old mapping removed\": {\n",
            "      \"pass_rate\": 1.0,\n",
            "      \"passed\": 2,\n",
            "      \"total\": 2\n",
            "    }\n",
            "  },\n",
            "  \"mean_execution_time_ms\": 20168.0,\n",
            "  \"overall_success_rate\": 0.0,\n",
            "  \"pass_at_1\": 0.0,\n",
            "  \"successful_runs\": 0,\n",
            "  \"tool_usage\": {\n",
            "    \"create_event\": 1,\n",
            "    \"get_calendar_list\": 2,\n",
            "    \"list_events\": 1,\n",
            "    \"move_event\": 1,\n",
            "    \"patch_event\": 1,\n",
            "    \"update_calendar_in_list\": 1\n",
            "  },\n",
            "  \"total_runs\": 2,\n",
            "  \"total_verifiers_checked\": 10,\n",
            "  \"total_verifiers_passed\": 6,\n",
            "  \"verifier_level_pass_rate\": 0.6\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Load and display results\n",
        "import glob\n",
        "import json\n",
        "\n",
        "# Find most recent results file\n",
        "result_files = glob.glob(\"benchmark_results_*.json\")\n",
        "if result_files:\n",
        "    latest_file = max(result_files)\n",
        "    print(\"File Name: \", latest_file)\n",
        "    with open(latest_file, 'r') as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    print(results['statistics'])\n",
        "    print(json.dumps(results['statistics'], indent=2, sort_keys=True))\n",
        "else:\n",
        "    print(\"No results files found. Run the benchmark first.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}