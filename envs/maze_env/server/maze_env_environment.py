# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

"""
Maze Environment Implementation.

A simple gridworld maze with walls, a start cell, and an exit.
"""

from typing import Any, Optional, Tuple
from uuid import uuid4

# Support both in-repo and standalone imports
try:
    # In-repo imports (when running from OpenEnv repository)
    from openenv.core.env_server.interfaces import Environment
    from openenv.core.env_server.types import State
    from ..models import MazeAction, MazeObservation, MazeState
except ImportError:
    # Standalone imports (when environment is standalone with openenv-core from pip)
    from openenv_core.env_server.interfaces import Environment
    from openenv_core.env_server.types import State
    from models import MazeAction, MazeObservation, MazeState

from .maze import Maze, Status, Render

try:
    import numpy as np
except ImportError as e:
    raise ImportError(
        "Numpy is not installed. "
        "Please install it following instructions at: "
        "pip install numpy"
    ) from e


DEFAULT_MAZE = np.array(
    [
        [0, 0, 0, 0, 0, 1, 0, 0],
        [1, 1, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 1],
        [0, 1, 1, 1, 1, 1, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 0],
        [1, 0, 1, 1, 1, 0, 0, 0],
        [0, 0, 0, 0, 1, 0, 1, 0],
        [0, 1, 1, 0, 0, 0, 0, 0],
    ],
    dtype=int,
)


class MazeEnvironment(Environment):
    """
    A maze environment built on a simple gridworld.

    The agent starts at a configurable start cell and must reach the exit cell.
    """

    # Enable concurrent WebSocket sessions.
    # Set to True if your environment isolates state between instances.
    # When True, multiple WebSocket clients can connect simultaneously, each
    # getting their own environment instance (when using factory mode in app.py).
    SUPPORTS_CONCURRENT_SESSIONS: bool = True

    def __init__(
        self,
        maze_array: Optional[np.ndarray] = None,
        start_cell: Tuple[int, int] = (0, 0),
        exit_cell: Optional[Tuple[int, int]] = None,
    ):
        """Initialize the Maze environment."""
        self._maze_array = np.array(
            maze_array if maze_array is not None else DEFAULT_MAZE, dtype=int
        )
        nrows, ncols = self._maze_array.shape

        self._start_cell = (int(start_cell[0]), int(start_cell[1]))
        self._exit_cell = (
            (ncols - 1, nrows - 1) if exit_cell is None else (int(exit_cell[0]), int(exit_cell[1]))
        )

        self.env = Maze(
            maze=self._maze_array,
            start_cell=self._start_cell,
            exit_cell=self._exit_cell,
            rendering=Render.NOTHING,
        )

        self._state = MazeState(episode_id=str(uuid4()), step_count=0)
        self._reset_count = 0
        self._sync_state(done=False)

    def reset(
        self,
        seed: Optional[int] = None,
        start_cell: Optional[Tuple[int, int]] = None,
    ) -> MazeObservation:
        """
        Reset the environment.

        Returns:
            MazeObservation with initial maze state
        """
        if seed is not None:
            np.random.seed(seed)

        self.env.reset(self._start_cell if start_cell is None else start_cell)
        self._state = MazeState(episode_id=str(uuid4()), step_count=0)
        self._reset_count += 1
        self._sync_state(done=False)

        return self._build_observation(reward=0.0, done=False, status=Status.PLAYING)

    def step(
        self,
        action: MazeAction
    ) -> MazeObservation:
        """
        Execute a step in the environment.

        Args:
            action: MazeAction containing the action to take

        Returns:
            MazeObservation with the result of the action
        """
        self._state.step_count += 1

        _, reward, status = self.env.step(int(action.action))
        done = status in (Status.WIN, Status.LOSE)
        self._sync_state(done=done)

        return self._build_observation(reward=reward, done=done, status=status)


    def _build_observation(
        self, reward: float, done: bool, status: Status
    ) -> MazeObservation:
        legal_actions = (
            [int(a) for a in self.env.possible_actions()] if not done else []
        )

        return MazeObservation(
            current_position=[int(x) for x in self.env.current_cell],
            legal_actions=legal_actions,
            reward=reward,
            done=done,
            metadata={
                "maze": self._maze_array.tolist(),
                "status": status.name.lower(),
                "exit_cell": list(self.env.exit_cell),
                "step": self._state.step_count,
            },
        )

    def _sync_state(self, done: bool) -> None:
        self._state.done = done
        self._state.current_position = [int(x) for x in self.env.current_cell]
        self._state.exit_cell = list(self.env.exit_cell)
        self._state.status = self.env.status.name.lower()

    @property
    def state(self) -> State:
        """
        Get the current environment state.

        Returns:
            Current State with episode_id and step_count
        """
        return self._state
